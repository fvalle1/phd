{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys, gc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "sys.path.append(\"/home/fvalle/phd/master_thesis/\")\n",
    "sys.path.append(\"/home/fvalle/phd/master_thesis/hsbm/\")\n",
    "from hsbmpy import get_max_available_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = 'disease_type'\n",
    "algorithm = \"topsbm\"\n",
    "directory='/home/fvalle/phd/datasets/merged'\n",
    "L = get_max_available_L(directory, algorithm)-1\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'tissue_hd'\n",
    "\n",
    "df_topics = pd.read_csv(\"%s/%s_level_%d_topic-dist.csv\"%(algorithm,algorithm,L)).set_index('doc').drop('i_doc', axis=1)\n",
    "df_words = pd.read_csv(\"%s/%s_level_%d_word-dist.csv\"%(algorithm,algorithm,L), index_col=0)\n",
    "df_words.index=[g[:15] for g in df_words.index]\n",
    "df = pd.read_csv(\"mainTable_train.csv\", index_col=0).reindex(index=df_words.index)\n",
    "df = df.divide(df.sum(0),1).transpose().fillna(0)\n",
    "\n",
    "df_files=pd.read_csv(\"files.dat\", index_col=0)\n",
    "df_topics.insert(0,'tissue', df_files.reindex(index=df_topics.index)[label])\n",
    "df_topic_tissue = df_topics.groupby('tissue').mean()\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pst = pd.DataFrame(data=np.matmul(df.values,df_words.values), index = df.index, columns = df_words.columns)\n",
    "df_Pst = df_Pst.divide(df_Pst.sum(1), 0)\n",
    "predictions = np.array(list(map(lambda x: list(map(lambda y: entropy(x, y), df_topic_tissue.astype(float).values)), df_Pst.astype(float).values)))\n",
    "\n",
    "df_Pst.insert(0,'tissue', df_files.reindex(index=df_Pst.index)[label])\n",
    "reals = np.unique(df_Pst.tissue, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy projecting score: {accuracy_score(reals, np.argmin(predictions, axis=1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN based predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import binary_crossentropy,mean_squared_error, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import plot_model,to_categorical\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.client.device_lib import list_local_devices\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import os,sys, gc\n",
    "list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=df_files.copy()\n",
    "df_labels=df_labels.reindex(index=df_topics.index)\n",
    "\n",
    "uniq = len(df_labels[label].unique())\n",
    "\n",
    "X_train = df_topics.drop('tissue',1).divide(df_topics.drop('tissue',1).mean(0),1).values.astype(float)\n",
    "Y_train = to_categorical(np.unique(df_labels[label], return_inverse=True)[1])\n",
    "classes=np.unique(df_labels[df_labels.index.isin(df.index)][label], return_inverse=True)[0]\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "X_tm_train, X_tm_test, Y_tm_train, Y_tm_test = train_test_split(X_train, Y_train, random_state=42, train_size=0.95)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_tm_train.shape, Y_tm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "os.system(\"rm -rf log.csv\")\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, mode='min', patience=25)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=100, input_dim=inputs, use_bias=True, bias_initializer='ones', activation=\"relu\"))\n",
    "model.add(Dense(units=uniq, input_dim=inputs, activation=\"softmax\"))\n",
    "model.compile(loss=binary_crossentropy, optimizer=SGD(lr=0.01, momentum=0.4), metrics=['accuracy', 'AUC'])\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tm_train, Y_tm_train, epochs=1000, batch_size=500, verbose=1, validation_split=0.1, callbacks=[csv_logger, es], shuffle=True, use_multiprocessing=True, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"log.csv\", sep=\",\")[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_tm_test, Y_tm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate on non used on topsbm training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_table = pd.read_csv(\"mainTable_test.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only HV genes\n",
    "df_test = df_test_table.reindex(index=df_words.index)\n",
    "\n",
    "df_test = df_test.divide(df_test.sum(0),1).transpose().fillna(0)\n",
    "\n",
    "df_test = pd.DataFrame(data=np.matmul(df_test.values,df_words.values), index=df_test.index, columns=df_words.columns)\n",
    "df_test=df_test.divide(df_test.mean(axis=0), axis=1) #normalize P(t|d)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(df_files.reindex(index=df_test.index)[label])\n",
    "X_test = df_test.values\n",
    "Y_test = to_categorical([np.where(classes==t)[0][0] for t in df_files.reindex(index=df_test.index)[label].values.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=2, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=classes, columns=classes).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_pred, y_test in zip(model.predict_classes(X_test), Y_test):\n",
    "    results.at[classes[y_test.argmax()], classes[class_pred]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(results.divide(results.sum(1),0), annot=False)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"predict.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "tissue='Breast'\n",
    "df_topic_tissue.transpose().plot(ax=ax[0], marker='o', ms=5)\n",
    "df_topics[df_topics.index.isin(df_files[df_files['primary_site']==tissue].index)].drop('tissue', 1).transpose().plot(ax=ax[1])\n",
    "df_topics[df_topics.index.isin(df_files[df_files['primary_site']==tissue].index)].drop('tissue', 1).transpose().mean(1).plot(ax=ax[1], lw=9, ls=':')\n",
    "ax[1].set_title(tissue)\n",
    "#ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n",
    "ax[0].set_ylim(0,0.8)\n",
    "ax[1].set_ylim(0,0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sbmtm import sbmtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topsbm/topsbm.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsbm = pd.DataFrame(index=model.words, columns=model.documents).fillna(0)\n",
    "for e, count in zip(model.g.get_edges(),model.g.properties[('e', 'count')].get_array()):\n",
    "    df_hsbm.at[df_hsbm.index[e[1]-1000], df_hsbm.columns[e[0]]]=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(index=df_hsbm.columns, columns=df_hsbm.index).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
