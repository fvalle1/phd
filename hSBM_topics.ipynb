{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib.ticker as mticker\n",
    "import sys, os\n",
    "from hsbmpy import plot_topic_size, get_max_available_L\n",
    "from hypergeom import parameters_for_hypergeometric, build_map, plot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"/home/jovyan/work/phd/datasets/gtex/10\"\n",
    "os.chdir(directory)\n",
    "sys.path.append('/home/jovyan/work/phd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_max_available_L(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,L+1):\n",
    "    plot_topic_size(directory,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=0,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv=pd.DataFrame(data=[df.mean(1), df.var(1),df.apply(lambda x: len([x[x>0]])/float(len(x)), 1)], index=['average', 'var', 'O']).transpose()\n",
    "df_mv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,L+1):\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    ax = fig.subplots(1,2)\n",
    "    candles = get_candles(directory,l,df_mv,ax[0])\n",
    "    candlestick2_ohlc(ax[0], candles['open'],candles['high'],candles['low'],candles['close'],width=0.6,colordown='b')\n",
    "    ax[1].hist((np.array(candles['open'])+np.array(candles['close']))/2, weights=candles['size'], range=(-0.05,1.05), bins=10, histtype='step')\n",
    "    ax[1].set_xlabel(\"$O_i\", fontsize=18)\n",
    "    plt.show()\n",
    "    fig.savefig(\"%s/topic_Ocandles_level_%d.pdf\"%(directory,l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geneontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneontology import get_ontology_df, ensg_to_symbol\n",
    "from tableanalyser import get_symbol\n",
    "import gseapy as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, geneontology,tableanalyser\n",
    "importlib.reload(geneontology)\n",
    "importlib.reload(tableanalyser)\n",
    "from geneontology import get_ontology_df, ensg_to_symbol\n",
    "from tableanalyser import get_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=L-1\n",
    "algorithm = \"topsbm\"\n",
    "df_topics = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_topics.csv\")\n",
    "df_topics_smooth = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_word-dist.csv\",index_col=0)\n",
    "df_topics_smooth.index = [g[:15] for g in df_topics_smooth.index]\n",
    "print(f\"level {l} with {df_topics.shape[1]} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_over_thr(topic_name, q=0.05):\n",
    "    topic = df_topics_smooth[topic_name]\n",
    "    topic = topic[topic>0]\n",
    "    topic = topic[topic>topic.quantile(q=q)]\n",
    "    return topic.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbols= pd.read_csv(\"https://www.genenames.org/cgi-bin/download/custom?col=gd_hgnc_id&col=gd_app_sym&col=gd_pub_ensembl_id&col=md_ensembl_id&col=md_eg_id&status=Approved&status=Entry%20Withdrawn&hgnc_dbtag=on&order_by=gd_app_sym_sort&format=text&submit=submit\", index_col=[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sea():\n",
    "    for g in df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]:\n",
    "        yield get_symbol(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gback.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x+'\\n') if len(x)>1 else None, get_sea()))\n",
    "    \n",
    "with open(\"gback_ensg.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x[:15]+'\\n')if len(x)>1 else None, df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gs.get_library_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.gsea-msigdb.org/gsea/downloads.jsp\n",
    "gene_sets = ['GO_Molecular_Function_2018',\n",
    "             'GO_Biological_Process_2018',\n",
    "             'GO_Cellular_Component_2018',\n",
    "             'Human_Phenotype_Ontology',\n",
    "             'WikiPathways_2019_Human',\n",
    "             '/home/jovyan/work/phd/MSigDB/c1.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c2.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c3.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c4.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c5.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c6.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c7.all.v7.1.symbols.gmt',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "threshhold = 5e-1\n",
    "cutoff = 5e-1\n",
    "background = len([g for g in get_sea()])\n",
    "os.system(\"mkdir -p gsea\")\n",
    "os.system(\"mkdir -p gsea/{}\".format(algorithm))\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"gsea/%s/gsea_level_%d_topic_%d.csv\"%(algorithm,l,itopic+1), index_col=[0])\n",
    "        print(topic)\n",
    "    except:\n",
    "        try:\n",
    "            gene_list = ensg_to_symbol(df_topics.loc[:,topic].dropna().values)\n",
    "            #gene_list = ensg_to_symbol(get_topic_over_thr(topic).index)\n",
    "            print(topic)\n",
    "            enriched_topic = get_ontology_df(gene_list, cutoff=cutoff, threshhold = threshhold, gene_sets = gene_sets, background=background)\n",
    "            enriched_topic = enriched_topic.sort_values(by=['Adjusted P-value'], ascending=True)[:20]\n",
    "            enriched_topic.to_csv(\"gsea/%s/gsea_level_%d_topic_%d.csv\"%(algorithm,l,itopic+1))\n",
    "        except:\n",
    "            print(*sys.exc_info())\n",
    "            continue\n",
    "    print(enriched_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "topic_pvalues = []\n",
    "topic_gos = []\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"gsea/%s/gsea_level_%d_topic_%d.csv\"%(algorithm,l,itopic+1))\n",
    "        if len(enriched_topic.index) >0:\n",
    "            p_val = np.sort(enriched_topic['Adjusted P-value'])[0]\n",
    "            topic_pvalues.append(-np.log10(p_val))\n",
    "            for goc in enriched_topic['Gene_set'][:10].unique():\n",
    "                topic_gos.append(goc)\n",
    "        print(topic)\n",
    "    except:\n",
    "        print(\"error\", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,15))\n",
    "x = np.arange(1,1+len(topic_pvalues))\n",
    "c, _, _ = plt.hist(topic_pvalues, histtype='step', lw=20, bins=45, color=\"gray\")\n",
    "plt.vlines(-np.log10(0.05),0,np.max(c)*1.1, color=\"red\", ls='--', lw=10, label=\"$\\\\alpha=0.05$\")\n",
    "plt.xlabel('-log(P-value)', fontsize=35)\n",
    "plt.ylabel(\"number of topics\", fontsize=35)\n",
    "#plt.ylim(0,0.055)\n",
    "#plt.yscale('log')\n",
    "plt.legend(fontsize=35)\n",
    "plt.tick_params(which=\"both\",labelsize=35)\n",
    "fig.savefig(\"%s/pvalues_acrosstopic_%s_(%d).pdf\"%(directory,algorithm,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,20))\n",
    "gos, goscounts = np.unique(topic_gos, return_counts=True)\n",
    "plt.barh([\"\\n\".join(wrap(str(l).replace('_',' '),20)) for l in gos], goscounts)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tick_params(which=\"both\",labelsize=35)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"%s/pvalue_categories_%s_(%d).pdf\"%(directory,algorithm,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hypergeometric operlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "from sklearn.metrics import v_measure_score\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, hypergeom\n",
    "importlib.reload(hypergeom)\n",
    "from hypergeom import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm/topsbm_level_3_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm-log/topsbm-log_level_3_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_log_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_log_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgcna_list_topics = pd.read_csv(\"wgcna/wgcna_level_0_topics.csv\")\n",
    "gene_list = wgcna_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "wgcna_list=pd.Series(index=np.unique([g[:15] for g in gene_list]), dtype=str)\n",
    "for topic in wgcna_list_topics.columns:\n",
    "    wgcna_list[np.unique([g[:15] for g in wgcna_list_topics[topic].dropna()])]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_list_topics = pd.read_csv(\"tm/tm_level_0_topics.csv\")\n",
    "gene_list = tm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "tm_list=pd.Series(index=np.unique([g[:15] for g in gene_list]), dtype=str)\n",
    "for topic in tm_list_topics.columns:\n",
    "    tm_list[np.unique([g[:15] for g in tm_list_topics[topic].dropna()])]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list_topics = pd.read_csv(\"lda/lda_level_1_topics.csv\")\n",
    "gene_list = lda_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "lda_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in lda_list_topics.columns:\n",
    "    lda_list[lda_list.index.isin([g[:15] for g in lda_list_topics[topic].dropna()])]=topic\n",
    "lda_list=lda_list.reset_index().drop_duplicates(\"index\").set_index(\"index\")\n",
    "lda_list=pd.Series(index=lda_list.index, data=lda_list.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(first_name, last_name):\n",
    "    list_1 = globals()[f\"{first_name}_list\"]\n",
    "    list_2 = globals()[f\"{last_name}_list\"]\n",
    "\n",
    "    #to uniform\n",
    "    list_1 = list_1[list_1.index.isin(list_2.index)]\n",
    "    list_2 = list_2[list_2.index.isin(list_1.index)]\n",
    "    hyper_params = parameters_for_hypergeometric(list_1, list_2)\n",
    "    df_cmap = build_map(*hyper_params)\n",
    "    df_cmap[df_cmap<3]=0\n",
    "    df_cmap = df_cmap.sort_values(by=[t for t in df_cmap.columns], ascending=False)\n",
    "    plot_map(df_cmap, first_name=first_name, last_name=last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(\"hsbm\",\"tm\")\n",
    "run(\"hsbm\",\"lda\")\n",
    "run(\"hsbm\",\"wgcna\")\n",
    "run(\"tm\",\"lda\")\n",
    "run(\"tm\",\"wgcna\")\n",
    "run(\"lda\",\"wgcna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hsbm & tm %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(tm_list), tm_list))\n",
    "print(\"hsbm & lda %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(lda_list).dropna(), lda_list.reindex_like(hsbm_list).dropna()))\n",
    "print(\"hsbm & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(hsbm_list.reindex_like(wgcna_list), wgcna_list))\n",
    "print(\"tm & lda %.3f \\\\\\\\ \\hline\"%v_measure_score(tm_list.reindex_like(lda_list).dropna(), lda_list.reindex_like(tm_list).dropna()))\n",
    "print(\"tm & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(tm_list.reindex_like(wgcna_list).dropna(), wgcna_list.reindex_like(tm_list).dropna()))\n",
    "print(\"lda & wgcna %.3f \\\\\\\\ \\hline\"%v_measure_score(lda_list.reindex_like(wgcna_list).dropna(), wgcna_list.reindex_like(lda_list).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in hsbm_list[hsbm_list==\"Topic 1\"].index:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
