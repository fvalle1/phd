{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib.ticker as mticker\n",
    "import sys, os\n",
    "from hsbmpy import plot_topic_size, get_max_available_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"/home/jovyan/work/phd/datasets/gtex/10\"\n",
    "os.chdir(directory)\n",
    "sys.path.append('/home/jovyan/work/phd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_max_available_L(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,L+1):\n",
    "    plot_topic_size(directory,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=0,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv=pd.DataFrame(data=[df.mean(1), df.var(1),df.apply(lambda x: len([x[x>0]])/float(len(x)), 1)], index=['average', 'var', 'O']).transpose()\n",
    "df_mv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0,L+1):\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    ax = fig.subplots(1,2)\n",
    "    candles = get_candles(directory,l,df_mv,ax[0])\n",
    "    candlestick2_ohlc(ax[0], candles['open'],candles['high'],candles['low'],candles['close'],width=0.6,colordown='b')\n",
    "    ax[1].hist((np.array(candles['open'])+np.array(candles['close']))/2, weights=candles['size'], range=(-0.05,1.05), bins=10, histtype='step')\n",
    "    ax[1].set_xlabel(\"$O_i\", fontsize=18)\n",
    "    plt.show()\n",
    "    fig.savefig(\"%s/topic_Ocandles_level_%d.pdf\"%(directory,l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geneontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneontology import get_ontology_df, ensg_to_symbol\n",
    "from tableanalyser import get_symbol\n",
    "import gseapy as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, geneontology,tableanalyser\n",
    "importlib.reload(geneontology)\n",
    "importlib.reload(tableanalyser)\n",
    "from geneontology import get_ontology_df, ensg_to_symbol\n",
    "from tableanalyser import get_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=L-1\n",
    "algorithm = \"topsbm\"\n",
    "df_topics = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_topics.csv\")\n",
    "df_topics_smooth = pd.read_csv(f\"{directory}/{algorithm}/{algorithm}_level_{l}_word-dist.csv\",index_col=0)\n",
    "df_topics_smooth.index = [g[:15] for g in df_topics_smooth.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_over_thr(topic_name, q=0.75):\n",
    "    topic = df_topics_smooth[topic_name]\n",
    "    topic = topic[topic>0]\n",
    "    topic = topic[topic>topic.quantile(q=q)]\n",
    "    return topic.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbols= pd.read_csv(\"https://www.genenames.org/cgi-bin/download/custom?col=gd_hgnc_id&col=gd_app_sym&col=gd_pub_ensembl_id&col=md_ensembl_id&col=md_eg_id&status=Approved&status=Entry%20Withdrawn&hgnc_dbtag=on&order_by=gd_app_sym_sort&format=text&submit=submit\", index_col=[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sea():\n",
    "    for g in df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]:\n",
    "        yield get_symbol(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gback.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x+'\\n')if len(x)>1 else None, get_sea()))\n",
    "    \n",
    "with open(\"gback_ensg.txt\",'w') as f:\n",
    "    list(map(lambda x: f.writelines(x[:15]+'\\n')if len(x)>1 else None, df_topics.values.ravel()[[str(s)!='nan' for s in df_topics.values.ravel()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.get_library_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.gsea-msigdb.org/gsea/downloads.jsp\n",
    "gene_sets = ['GO_Molecular_Function_2018',\n",
    "             'GO_Biological_Process_2018',\n",
    "             'GO_Cellular_Component_2018',\n",
    "             'Human_Phenotype_Ontology',\n",
    "             'WikiPathways_2019_Human',\n",
    "             '/home/jovyan/work/phd/MSigDB/c1.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c2.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c3.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c4.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c5.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c6.all.v7.1.symbols.gmt',\n",
    "             '/home/jovyan/work/phd/MSigDB/c7.all.v7.1.symbols.gmt',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 5e-1\n",
    "cutoff = 5e-1\n",
    "background = len([g for g in get_sea()])\n",
    "os.system(\"mkdir -p gsea\")\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"gsea/gsea_level_%d_topic_%d.csv\"%(l,itopic+1), index_col=[0])\n",
    "        print(topic)\n",
    "    except:\n",
    "        try:\n",
    "            #gene_list = ensg_to_symbol(df_topics.loc[:,topic].dropna().values)\n",
    "            gene_list = ensg_to_symbol(get_topic_over_thr(topic).index)\n",
    "            print(topic)\n",
    "            enriched_topic = get_ontology_df(gene_list, cutoff=cutoff, threshhold = threshhold, gene_sets = gene_sets, background=background)\n",
    "            enriched_topic = enriched_topic.sort_values(by=['Adjusted P-value'], ascending=True)[:20]\n",
    "            enriched_topic.to_csv(\"gsea/gsea_level_%d_topic_%d.csv\"%(l,itopic+1))\n",
    "        except:\n",
    "            print(*sys.exc_info())\n",
    "            continue\n",
    "    print(enriched_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pvalues = []\n",
    "topic_gos = []\n",
    "for itopic,topic in enumerate(df_topics.columns):\n",
    "    try:\n",
    "        enriched_topic = pd.read_csv(\"%s/gsea/gsea_level_%d_topic_%d.csv\"%(directory,l,itopic+1))\n",
    "        if len(enriched_topic.index) >0:\n",
    "            p_val = np.sort(enriched_topic['Adjusted P-value'])[0]\n",
    "            topic_pvalues.append(-np.log10(p_val))\n",
    "            for goc in enriched_topic['Gene_set'][:10].unique():\n",
    "                topic_gos.append(goc)\n",
    "        print(topic)\n",
    "    except:\n",
    "        print(\"error\", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "x = np.arange(1,1+len(topic_pvalues))\n",
    "c, _, _ = plt.hist(topic_pvalues, histtype='step', lw=2)\n",
    "plt.plot([-np.log10(0.05) for _ in np.linspace(1,10,num=10)],np.arange(0,np.max(c)+5,(np.max(c)+5)/10), ls='--', lw=5, label=\"$\\\\alpha=0.05$\")\n",
    "plt.xlabel('-log(P-value)', fontsize=16)\n",
    "plt.ylabel(\"number of topics\")\n",
    "#plt.ylim(0,0.055)\n",
    "#plt.yscale('log')\n",
    "plt.legend(fontsize=16)\n",
    "fig.savefig(\"%s/pvaluescrosstopic(%d).png\"%(directory,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "gos, goscounts = np.unique(topic_gos,return_counts=True)\n",
    "plt.barh([\"\\n\".join(wrap(str(l).replace('_',' '),20)) for l in gos], goscounts)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig(\"%s/pvaluecategories(%d).pdf\"%(directory,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGCNA vs hSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "from sklearn.metrics import v_measure_score\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm/topsbm_level_3_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_list_topics = pd.read_csv(\"topsbm-log/topsbm-log_level_2_topics.csv\")\n",
    "gene_list = hsbm_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "hsbm_log_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in hsbm_list_topics.columns:\n",
    "    hsbm_log_list[[g[:15] for g in hsbm_list_topics[topic].dropna()]]=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgcna_list = pd.read_csv(\"wgcna/wgcna_level_0_word-dist.csv\", index_col=0).apply(pd.Series.idxmax,axis=1)\n",
    "wgcna_list.index = [g[:15] for g in wgcna_list.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_list = pd.read_csv(\"tm/tm_level_0_word-dist.csv\", index_col=0).apply(pd.Series.idxmax,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list_topics = pd.read_csv(\"lda/lda_level_2_topics.csv\")\n",
    "gene_list = lda_list_topics.values.ravel().astype(str)\n",
    "gene_list = list(map(lambda g: g[:15],filter(lambda g: g!=\"nan\", gene_list)))\n",
    "lda_list=pd.Series(index=[g[:15] for g in gene_list], dtype=str)\n",
    "for topic in lda_list_topics.columns:\n",
    "    lda_list[lda_list.index.isin([g[:15] for g in lda_list_topics[topic].dropna()])]=topic\n",
    "lda_list=lda_list.reset_index().drop_duplicates(\"index\").set_index(\"index\")\n",
    "lda_list=pd.Series(index=lda_list.index, data=lda_list.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = hsbm_list\n",
    "list_2 = lda_list\n",
    "\n",
    "first_name = \"hsbm\"\n",
    "last_name = \"lda\"\n",
    "\n",
    "#to uniform\n",
    "list_1 = list_1[list_1.index.isin(list_2.index)]\n",
    "list_2 = list_2[list_2.index.isin(list_1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = len(list_1[list_1.index.isin(list_2.index)])\n",
    "pop_successes = {module:len(list_2[list_2==module]) for module in list_2.unique()}\n",
    "sample_sizes = {topic:len(list_1[list_1==topic]) for topic in list_1.unique()}\n",
    "num_successes = pd.DataFrame(index=list_1.unique(), columns=list_2.unique()).fillna(0)\n",
    "for g in list_2.index:\n",
    "    if g in list_1.index:\n",
    "        num_successes.at[list_1[g],list_2[g]]+=1\n",
    "num_successes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmap=pd.DataFrame(index=[\"Topic %d\"%(d+1) for d in range(len(list_1.unique()))],\n",
    "                     columns=[\"Topic %d\"%(d+1) for d in range(len(list_2.unique()))]).fillna(0.5)\n",
    "if \"wgcna\" in last_name:\n",
    "    df_cmap.columns=num_successes.columns\n",
    "for module, module_successes in zip(df_cmap.columns, num_successes.columns):\n",
    "    for topic, topic_successes in zip(df_cmap.index, num_successes.index):\n",
    "        x = num_successes.at[topic_successes,module_successes].astype(int) # number of successes\n",
    "        M = population_size # pop size\n",
    "        k = pop_successes[module_successes] # successes in pop\n",
    "        N = sample_sizes[topic_successes] # sample size\n",
    "        pval = hypergeom.sf(x-1, M, k, N)\n",
    "        df_cmap.at[topic,module]=-np.log10(float(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmap[df_cmap<2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cmap = df_cmap.sort_values(by=[c for c in df_cmap.columns], axis=0, ascending=True)\n",
    "#create a color palette with the same number of colors as unique values in the Source column\n",
    "network_pal = sns.color_palette('husl',n_colors=len(df_cmap.columns))\n",
    "\n",
    "#Create a dictionary where the key is the category and the values are the\n",
    "#colors from the palette we just created\n",
    "network_lut = dict(zip(df_cmap.columns, network_pal))\n",
    "network_col = df_cmap.columns.map(network_lut)\n",
    "#Create a dictionary where the key is the category and the values are the\n",
    "#colors from the palette we just created\n",
    "network_lut = dict(zip(df_cmap.columns, network_pal))\n",
    "network_col = df_cmap.columns.map(network_lut)\n",
    "\n",
    "cm = sns.clustermap(df_cmap, \n",
    "                    row_cluster=False, \n",
    "                    col_cluster=False, \n",
    "                    metric='euclidean', \n",
    "                    vmin=0, \n",
    "                    cmap='Blues_r', \n",
    "                    col_colors=network_col,\n",
    "                    mask=False,\n",
    "                   cbar_pos=(1.05,0.05,0.05,0.7))\n",
    "\n",
    "ax = cm.ax_heatmap\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "ax.set_ylabel(first_name, fontsize=35)\n",
    "ax.set_xlabel(last_name, fontsize=35)\n",
    "ax.set_xticklabels(df_cmap.columns, rotation=45)\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "cax = cm.ax_cbar\n",
    "cax.tick_params(labelsize=24)\n",
    "cax.set_title(\"-Log(P-value)\", fontsize=30)\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "cm.fig.suptitle('Algorithm comparison', fontsize=40)\n",
    "cm.savefig(f\"topics_logp_{first_name}_{last_name}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hsbm - lda %.3f\"%v_measure_score(list_1, list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(print,list_1[list_1==\"Topic 39\"].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hsbm - wgcna %.3f\"%v_measure_score(hsbm_list, wgcna_list))\n",
    "print(\"hsbm - tm %.3f\"%v_measure_score(hsbm_list.reindex_like(tm_list), tm_list))\n",
    "print(\"tm - wgcna %.3f\"%v_measure_score(tm_list, wgcna_list.reindex_like(tm_list)))\n",
    "print(\"hsbm - lda %.3f\"%v_measure_score(hsbm_list, lda_list.reindex_like(hsbm_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
