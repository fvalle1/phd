{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os, sys, gc\n",
    "import pickle\n",
    "\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from frontiers_colors import get_color\n",
    "from frontiers_analysis import heaps, load_tissue, save_model, mazzolini\n",
    "\n",
    "from tableanalyser import discretize_df_columns, plotvarmen, plotcv2mean, plotoversigmacv2, getovergenes, plotoverpoints\n",
    "from tacos_plot import scatterdense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, frontiers_analysis\n",
    "importlib.reload(frontiers_analysis)\n",
    "from frontiers_analysis import heaps, load_tissue, save_model, mazzolini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source =\"mca\"\n",
    "files = os.listdir(data_source)\n",
    "from frontiers_analysis import load_all_data, clean_df\n",
    "data = load_all_data(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontiers_analysis import get_files, cleanup\n",
    "#get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_excel(\"MCA_Figure2_Cell.Info.xlsx\", index_col=0)\n",
    "\n",
    "df_info['Tissue'] = list(map(lambda ann: ann.replace(\"Adult\",\"\"), df_info['Tissue'])) #remove adult or fetal\n",
    "df_info['Tissue'] = list(map(lambda ann: ann.replace(\"Fetal\",\"\"), df_info['Tissue'])) #remove adult or fetal\n",
    "df_info['Tissue'] = list(map(lambda ann: ann.replace(\"Neonatal\",\"\"), df_info['Tissue'])) #remove adult or fetal\n",
    "df_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file=pd.read_csv(\"MCA_CellAssignments.csv\", index_col=0).set_index('Cell.name')\n",
    "df_file['Cell_type'] = list(map(lambda ann: ann.split('(')[0].split(' ')[0], df_file['Annotation'])) #remove adult or fetal\n",
    "print(df_file.info())\n",
    "print(df_file['Tissue'].unique())\n",
    "print(df_file['Cell_type'].unique())\n",
    "df_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = df_file\n",
    "df_info[\"id\"] = df_file.index.values\n",
    "df_info.rename(columns={'Tissue':'tissue',\"id\": \"Cell_id\"}, inplace=True)\n",
    "df_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(lambda f: \"dge\" in f,  os.listdir(data_source)))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse organs and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files[0])\n",
    "\n",
    "saved = []\n",
    "frac_of = {}\n",
    "\n",
    "if \"mca\" in data_source:\n",
    "    data = pd.read_csv(f\"{data_source}/{files[0]}\", sep=\" \")\n",
    "    data = data[data.columns[data.columns.isin(df_info['Cell_id'])]]\n",
    "\n",
    "    #tissues = df_info[df_info['Cell_id'].isin(data.columns) & (df_info['Development_stage']=='Adult')]['tissue'].unique() # only adults\n",
    "    tissues = df_info[df_info['Cell_id'].isin(data.columns)]['tissue'].unique()\n",
    "\n",
    "if \"tm\" in data_source:\n",
    "    tissues = [files[0]]\n",
    "\n",
    "\n",
    "print(tissues)\n",
    "for tissue in tissues:\n",
    "    if \"mca\" in data_source:\n",
    "        df = data.reindex(columns=df_info[df_info['Cell_id'].isin(data.columns) & (df_info['tissue']==tissue)]['Cell_id'])\n",
    "        #df = df.divide(df.sum(0), 1).applymap(lambda cpm: np.log(cpm*1e6+1)) #log(cpm +1)\n",
    "    \n",
    "    if \"tm\" in data_source:\n",
    "        df = pd.read_csv(f\"{data_source}/{files[0]}\", sep=\",\", index_col=0) #tabula muris\n",
    "        df = clean_df(df) #tabula muris\n",
    "    \n",
    "    A = df.sum(axis=1)\n",
    "    O = df.apply(lambda x: len(x[x>0]), 1)\n",
    "    M = df.apply(np.sum, 0)\n",
    "    cell_zeros = df.astype(int).apply(lambda x: len(x[x==0]), 0)\n",
    "    gene_presence = df.apply(lambda x: len(x[~x.isna()]), 1).astype(int)\n",
    "    gene_presence_nonnull = df.apply(lambda x: len(x[~x.isna() & (x>0)]), 1).astype(int)\n",
    "    var = df.apply(lambda x: (x*x).sum(), 1)\n",
    "    \n",
    "    frac_of[tissue] = {'data': A,\n",
    "                            'N': len(M)}\n",
    "    \n",
    "    diffWords = df.apply(lambda x: len(x[x>0]), 0)\n",
    "    n_genes = {}\n",
    "    n_genes[tissue] = diffWords\n",
    "    \n",
    "    n_expressed_genes = pd.Series(index=df.index, data=np.zeros_like(df.index))\n",
    "    n_expressed_genes[A.sort_values(ascending=False).index[:100]]+=1\n",
    "    save_model(df, \"data\", tissue)\n",
    "    #mazzolini(M, A/A.sum(), tissue)\n",
    "    #null_model(df, M, A/gene_presence_nonnull)\n",
    "    #heaps(M, diffWords, tissue)\n",
    "    \n",
    "    saved.append(tissue)\n",
    "    df.to_csv(f\"{data_source}/mainTable_{tissue}.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[1:]:\n",
    "    print(file)\n",
    "    if \"mca\" in data_source:\n",
    "        data = pd.read_csv(f\"{data_source}/{file}\", sep=\" \")\n",
    "        data = data[data.columns[data.columns.isin(df_info['Cell_id'])]]\n",
    "\n",
    "        if len(data.columns) < 1:\n",
    "            print(f\"skipping {file} \\n\")\n",
    "            continue\n",
    "        #tissues = df_info[df_info['Cell_id'].isin(data.columns) & (df_info['Development_stage']=='Adult')]['tissue'].unique() # only adults\n",
    "        tissues = df_info[df_info['Cell_id'].isin(data.columns)]['tissue'].unique()\n",
    "\n",
    "    if \"tm\" in data_source:\n",
    "        data = pd.read_csv(f\"{data_source}/{file}\", sep=\",\", index_col=0)\n",
    "        tissues = [files[0]]\n",
    "    \n",
    "    print(tissues)\n",
    "    if len(tissues) < 1:\n",
    "        print(f\"no tissue found \\n\")\n",
    "        continue\n",
    "    for tissue in tissues:\n",
    "        \n",
    "        if \"mca\" in data_source:\n",
    "            df = data.reindex(columns=df_info[df_info['Cell_id'].isin(data.columns) & (df_info['tissue']==tissue)]['Cell_id'])\n",
    "        \n",
    "        if \"tm\" in data_source:\n",
    "            df = clean_df(data)\n",
    "        \n",
    "        if tissue in saved:\n",
    "            df = df.transpose().append(pd.read_csv(f\"{data_source}/mainTable_{tissue}.csv\", index_col=0, header=0).transpose(), ignore_index=False, sort=True).transpose().fillna(0)\n",
    "        \n",
    "        #df = df.divide(df.sum(0), 1).applymap(lambda cpm: np.log(cpm*1e6+1)) #log(cpm +1)\n",
    "        A_sub = df.sum(axis=1)\n",
    "        O_sub = df.apply(lambda x: len(x[x>0]), 1)\n",
    "        M_sub = df.apply(np.sum, 0)\n",
    "        cell_zeros_sub = df.apply(lambda x: len(x[x>0]), 0)\n",
    "        diffWords_sub = df.apply(lambda x: len(x[x>0]), 0)\n",
    "        \n",
    "        if tissue in frac_of.keys():\n",
    "            frac_of[tissue]['data'].add(A_sub, fill_value = 0)\n",
    "            frac_of[tissue]['N']+=len(M_sub)\n",
    "        else:\n",
    "            frac_of[tissue] = {'data': A_sub,\n",
    "                                  'N': len(M_sub)}\n",
    "\n",
    "        A = A.add(A_sub, fill_value=0)\n",
    "        O = O.add(O_sub, fill_value=0)\n",
    "        M = M.append(M_sub)\n",
    "        cell_zeros = cell_zeros.append(cell_zeros_sub)\n",
    "        diffWords = diffWords.append(diffWords_sub)\n",
    "        if tissue in n_genes.keys():\n",
    "            n_genes[tissue] = n_genes[tissue].append(diffWords_sub)\n",
    "        else:\n",
    "            n_genes[tissue]= diffWords_sub\n",
    "        \n",
    "        gene_presence = gene_presence.add(df.apply(lambda x: len(x[~x.isna()]), 1), fill_value=0)\n",
    "        gene_presence_nonnull_sub = df.apply(lambda x: len(x[~x.isna() & (x>0)]), 1).astype(int)\n",
    "        gene_presence_nonnull = gene_presence_nonnull.add(gene_presence_nonnull_sub, fill_value=0).astype(int)\n",
    "        var = var.add(df.apply(lambda x: (x*x).sum(), 1), fill_value=0)\n",
    "        \n",
    "        n_expressed_genes_sub = pd.Series(index=df.index, data=np.zeros_like(df.index))\n",
    "        n_expressed_genes_sub[A_sub.sort_values(ascending=False).index[:100]]+=1\n",
    "        n_expressed_genes = n_expressed_genes.add(n_expressed_genes_sub, fill_value=0)\n",
    "\n",
    "        save_model(df,\"data\",tissue)\n",
    "        #mazzolini(M_sub, A_sub/A_sub.sum(), tissue)\n",
    "        #null_model(df, M_sub, A_sub/gene_presence_nonnull_sub)\n",
    "        #heaps(M_sub, diffWords_sub, tissue)\n",
    "        saved.append(tissue)\n",
    "        df.to_csv(f\"{data_source}/mainTable_{tissue}.csv\", index=True, header=True)\n",
    "        print(f\"Handling {len(M)} cells\")\n",
    "\n",
    "        del df \n",
    "        del A_sub\n",
    "        del O_sub\n",
    "        del M_sub\n",
    "        del diffWords_sub\n",
    "        del gene_presence_nonnull_sub\n",
    "        gc.collect()\n",
    "        print(\"\\n\")\n",
    "    del tissues\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "means = A/gene_presence\n",
    "means_nozero = A/gene_presence_nonnull\n",
    "var = var/gene_presence - means*means\n",
    "f = (A/A.sum())\n",
    "O = O / gene_presence\n",
    "O = O.reindex_like(means)\n",
    "cv2 = var/means/means\n",
    "\n",
    "\n",
    "print(\"Saving data.pkl\")\n",
    "data = {\n",
    "    'means': means,\n",
    "    'var': var,\n",
    "    'freq': A/A.sum(),\n",
    "    'O': O,\n",
    "    'M': M,\n",
    "    'cv2': cv2,\n",
    "    'diffWords': diffWords,\n",
    "    'means_nonzero': means_nozero,\n",
    "    'n_expressed': n_expressed_genes,\n",
    "    'n_genes': n_genes,\n",
    "    'frac_of': frac_of,\n",
    "    'cell_zeros': cell_zeros\n",
    "}\n",
    "\n",
    "with open(\"data_all.pkl\",\"wb\") as file:\n",
    "    pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=M[~M.duplicated()].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mazzolini(M,A/A.sum(),\"Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_expressed_genes = data[\"n_expressed\"]\n",
    "with open(\"100_most_expressed_in_40_tissues.txt\", \"w\") as f:\n",
    "    list(map(lambda x: f.write(x+\"\\n\"),n_expressed_genes[n_expressed_genes>=40].sort_values(ascending=False).index[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genes_first_range_1_26_mca.txt\", \"w\") as file:\n",
    "    list(map(lambda g:file.write(g+\"\\n\"),data[\"freq\"].sort_values(ascending=False)[:26].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations with Tabula Muris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_organs = [\"Bladder\", \"Kidney\", \"Liver\", \"Lung\", \"Pancreas\", \"Spleen\"]\n",
    "\n",
    "organ = common_organs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.informatics.jax.org/marker\n",
    "df_gene_name = pd.read_csv(\"MGImarkerQuery_20200914_050053.txt\", sep=\"\\t\")\n",
    "nc = df_gene_name[df_gene_name[\"Feature Type\"]!=\"protein coding gene\"][\"Symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = load_all_data(\"tm\")[\"freq\"]\n",
    "mca = load_all_data(\"mca\")[\"freq\"]\n",
    "\n",
    "organ=\"all_abundances\"\n",
    "\n",
    "#tm = load_tissue(f\"{organ}-counts.csv\", data_source=\"tm\")[\"freq\"]\n",
    "#mca = load_tissue(f\"{organ}\", data_source=\"mca\")[\"freq\"]\n",
    "#tm = tm / tm.sum()\n",
    "#mca = mca / mca.sum()\n",
    "\n",
    "tm = tm[tm.index.isin(mca.index)]\n",
    "mca = mca[mca.index.isin(tm.index)]\n",
    "tm = pd.Series(name='tm',index=tm.sort_values(ascending=False).index, data=range(1,1+len(tm)))\n",
    "mca = pd.Series(name='mca',index=mca.sort_values(ascending=False).index, data=range(1, len(mca)+1))\n",
    "\n",
    "mca = mca.reindex_like(tm).dropna()\n",
    "tm = tm.reindex_like(mca).dropna()\n",
    "\n",
    "tm_nc = tm[tm.index.isin(nc)]\n",
    "mca_nc = mca[mca.index.isin(nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_regime = pd.DataFrame()\n",
    "first_regime.insert(0,\"tm\",list(filter(lambda g: \"Olfr\" not in g, tm.sort_values(ascending=False).index))[:49])\n",
    "first_regime.insert(0,\"mca\",list(filter(lambda g: \"Olfr\" not in g, mca.sort_values(ascending=False).index))[:49])\n",
    "first_regime.to_csv(\"common_first_regime_noOlfr.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "ax.scatter(mca.values,tm.values, c=\"gray\", s=225, alpha=0.5)\n",
    "#scatterdense(mca.fillna(0).astype(float),tm.fillna(0).astype(float), ax=ax)\n",
    "\n",
    "#ax.scatter(mca_nc.values,tm_nc.values, c=\"red\", s=225, alpha=0.5)\n",
    "\n",
    "bin_avg, bin_edges, _ = stats.binned_statistic(mca.values, tm.values,\"mean\", bins=np.linspace(1,2e4,20))\n",
    "ax.plot(np.linspace(0,len(mca)),np.linspace(0,len(mca)), lw=15, ls=\"--\", label=\"diagonal\")\n",
    "ax.hlines(bin_avg, bin_edges[:-1], bin_edges[1:], lw=15, ls=\"-\", color=\"orange\", label=\"binned average\")\n",
    "\n",
    "\n",
    "ax.set_title(f\"{organ} (Pearson = %.2f)\"%(pearsonr(mca.values, tm.values)[0]), fontsize=35)\n",
    "ax.set_xlabel(\"Mouse Cell Atlas' Rank\", fontsize=35)\n",
    "ax.set_ylabel(\"Tabula Muris' Rank\", fontsize=35)\n",
    "\n",
    "#ax.set_xscale(\"log\")\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_xlim(mca.min(),mca.max())\n",
    "ax.set_ylim(tm.min(),tm.max())\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.legend(loc=\"lower right\", fontsize=35)\n",
    "fig.savefig(f\"rank_correlation_{organ}.pdf\")\n",
    "fig.savefig(f\"rank_correlation_{organ}.eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both = pd.DataFrame()\n",
    "df_both=df_both.append(mca)\n",
    "df_both=df_both.append(tm)\n",
    "df_both=df_both.transpose()\n",
    "\n",
    "pop = df_both.index\n",
    "sampled=df_both.sort_values(by=\"mca\", ascending=True)[:500].index\n",
    "successes = df_both.sort_values(by=\"tm\", ascending=True)[:500].index\n",
    "\n",
    "x = np.isin(successes, sampled).astype(int).sum() # number of successes\n",
    "M = len(pop) # pop size\n",
    "k = len(successes) # successes in pop\n",
    "N = len(sampled) # sample size\n",
    "pval = hypergeom.sf(x-1, M, k, N)\n",
    "#-np.log10(float(pval))\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmap=pd.DataFrame(index=common_organs, columns=common_organs).fillna(0.5)\n",
    "genes_list = {}\n",
    "lim = 18\n",
    "d_lim = 2000\n",
    "\n",
    "rang=range(0,82)\n",
    "\n",
    "mca = load_tissue(organ)[\"freq\"]\n",
    "tm = load_tissue(organ+\"-counts.csv\",  data_source=\"tm\")[\"freq\"]\n",
    "tm_all = tm[tm.index.isin(mca.index)]\n",
    "mca_all = mca[mca.index.isin(tm.index)]\n",
    "common_genes = mca_all.index\n",
    "\n",
    "population_size = len(mca_all)\n",
    "\n",
    "\n",
    "for tissue_1 in df_cmap.columns:\n",
    "    genes_list[\"tm\"]=load_tissue(tissue_1+\"-counts.csv\", data_source=\"tm\")[\"freq\"]\n",
    "    for tissue_2 in df_cmap.index:\n",
    "        print(tissue_1, tissue_2)\n",
    "        genes_list[\"mca\"]=load_tissue(tissue_2)[\"freq\"]\n",
    "        tm = pd.Series(name='tm',index=genes_list[\"tm\"].sort_values(ascending=True).index, data=range(1,1+len(genes_list[\"tm\"])))\n",
    "        mca = pd.Series(name='mca',index=genes_list[\"mca\"].sort_values(ascending=True).index, data=range(1, len(genes_list[\"mca\"])+1))\n",
    "        tm = tm[tm.index.isin(common_genes)]\n",
    "        mca = mca[mca.index.isin(common_genes)]\n",
    "\n",
    "        x = np.isin(tm.index[rang], mca.index[rang]).astype(int).sum() # number of successes\n",
    "        M = population_size # pop size\n",
    "        k = len(mca.index[rang]) # successes in pop\n",
    "        N = len(tm.index[rang]) # sample size\n",
    "        pval = hypergeom.sf(x-1, M, k, N)\n",
    "        print(x, M, k, N, pval)\n",
    "        log_pval = -np.log10(float(pval))\n",
    "        if log_pval < -np.log10(5e-1):\n",
    "            log_pval=0\n",
    "        df_cmap.at[tissue_1,tissue_2]=log_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df_cmap)\n",
    "ax.set_title(\"-Log(P-value)\\n Tabula Muris vs Mouse Cell Atlas\", fontsize=25)\n",
    "\n",
    "fig= ax.get_figure()\n",
    "fig.set_size_inches(18,15)\n",
    "fig.savefig(\"logp_regim1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontiers_analysis import load_pickle\n",
    "mca_genes = load_pickle(\"mca/data_all.pkl\")[\"freq\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_genes = pd.read_csv(\"FACS/Aorta-counts.csv\", index_col=0).index[np.load(\"bad_genes_0.npy\")]\n",
    "isin = np.isin(mca_genes,bad_genes)\n",
    "with open(\"bad_genes_common.csv\", \"w\") as file:\n",
    "    list(map(lambda g: file.write(g+\"\\n\"),mca_genes[isin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(pd.read_csv(\"rs_gtex.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# Fraction of trascriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded = {}\n",
    "\n",
    "frac_of = data[\"frac_of\"]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(18,15))\n",
    "for tissue in frac_of.keys():\n",
    "    #if \"Lactation\" in tissue:\n",
    "    #    continue\n",
    "    A_tissue = (frac_of[tissue]['data'] / frac_of[tissue]['N']).sort_values(ascending=False)\n",
    "    A_tissue_sum = np.cumsum(A_tissue.values) / A_tissue.sum() #h thr\n",
    "    ax.plot(A_tissue_sum, label = tissue, c=get_color(tissue), lw=15, alpha=.7)\n",
    "    #if len(A_tissue_sum) < 2:\n",
    "    #    continue\n",
    "    thresholded[tissue] = A_tissue_sum[99]\n",
    "    #thresholded[tissue] = np.argwhere(A_tissue_sum>=0.4).ravel()[0] #v thr\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1, 3e4)\n",
    "ax.set_xlabel(\"Number of genes\", fontsize=35)\n",
    "ax.set_ylabel(\"Fraction of trascriptome described\", fontsize=35)\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "fig.savefig(\"fracof_mca.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_thr = pd.DataFrame(data= thresholded.items()).set_index(0).sort_values(1, ascending=False)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "ax.bar(gene_to_thr.index, gene_to_thr.values.ravel())\n",
    "ax.tick_params(rotation=90)\n",
    "\n",
    "ax.set_ylabel(\"Fraction of trascriptome\\n described by 100 genes\", fontsize=24)\n",
    "#ax.set_ylabel(\"Number of genes\\n to describe 40% of trascriptome\", fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"frac_of_100genes.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index=gene_to_thr.sort_values(1).index, data=range(len(gene_to_thr)), columns=['MCA']).to_csv(\"trascriptome_sort.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort = pd.read_csv(\"trascriptome_sort.csv\", index_col=0).dropna(how='any', axis=0).astype(int)\n",
    "df_sort['MCA'] = range(len(df_sort))\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.scatter(*df_sort.values.T, s=90)\n",
    "plt.xlim(-1,15)\n",
    "plt.ylim(-1,15)\n",
    "\n",
    "plt.xlabel(\"MCA\", fontsize=20)\n",
    "plt.ylabel(\"tabula_muris\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in frac_of['MammaryGland.Lactation']['data'].sort_values(ascending=False).index[:10]:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(45,35))\n",
    "organ_names=n_genes.keys()\n",
    "n_genes_all=list(map(lambda organ: organ[1].values,n_genes.items()))\n",
    "box1=plt.boxplot(np.array(n_genes_all), vert=True, patch_artist=True,notch=True,\n",
    "        boxprops=dict(facecolor='magenta', color='magenta'))\n",
    "ax.set_xticklabels(labels=organ_names,rotation=75)\n",
    "ax.tick_params(axis='y', labelsize=24)\n",
    "ax.tick_params(axis='x', labelsize=18)\n",
    "plt.title('Number of genes detected per cell', fontsize=28)\n",
    "plt.xlabel('Organ', fontsize=28)\n",
    "plt.ylabel('N genes', fontsize=28)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig(\"boxplot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "for tissue in data[\"frac_of\"].keys():\n",
    "    try:\n",
    "        info = load_tissue(tissue, data_source=data_source)\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "        continue \n",
    "    if \"Lactation\" in tissue:\n",
    "        continue\n",
    "    f = info[\"freq\"]\n",
    "    f = f[~f.index.isin(nc)]\n",
    "    ax.plot(f.sort_values(ascending=False).values, label=tissue, c=get_color(tissue), lw=15, alpha=.7)\n",
    "    \n",
    "x =np.linspace(1,6e4,10)\n",
    "\n",
    "exp = 0.8\n",
    "ax.plot(x, 1e-1*np.power(x, -0.8), lw=20, c='gray', ls='--')\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.annotate('$k*i^{-%.1f}$'%exp, (1e2,1e-2), fontsize=35)\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=18, ncol=2)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.set_xlim(1,1e5)\n",
    "ax.set_ylim(1e-9,1e0)\n",
    "ax.set_xlabel(\"Rank, $i$\", fontsize=35)\n",
    "ax.set_ylabel(\"Frequency, $f_i$\", fontsize=35)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"zipf_alltissue_{data_source}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog = True\n",
    "filter_mammaryLactation = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "for tissue in data[\"frac_of\"].keys():\n",
    "    try:\n",
    "        info = load_tissue(tissue, data_source=data_source)\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "        continue\n",
    "    if (\"Lactation\" in tissue) and filter_mammaryLactation:\n",
    "        continue\n",
    "    M = info[\"M\"]\n",
    "    diff= info[\"diffWords\"]\n",
    "    skip_bins = 5\n",
    "    n_bins=35\n",
    "    if len(M) <= n_bins:\n",
    "        continue\n",
    "    bin_means, bin_edges, binnumber = stats.binned_statistic(M, diff,statistic='mean', bins=np.logspace(np.log10(M.min()),np.log10(max(M)), n_bins))\n",
    "    bin_stds, _, _ = stats.binned_statistic(M, diff,statistic='std', bins=np.linspace(M.min(),np.quantile(M, 0.9), n_bins))\n",
    "    x = ((bin_edges[:-1]+bin_edges[1:])/2.)[:-skip_bins]\n",
    "    y = bin_means[:-skip_bins]\n",
    "    ax.plot(x, y, marker='o', lw=5, ms=25, alpha=0.8, c=get_color(tissue), label=tissue)\n",
    "    #ax.errorbar(x,y , bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "\n",
    "if \"mca\" in data_source:\n",
    "    ax.set_xlabel(\"UMI per cell\", fontsize=35)\n",
    "else:\n",
    "    ax.set_xlabel(\"Reads per cell\", fontsize=35)\n",
    "ax.set_ylabel(\"Number of expressed genes\", fontsize=35)\n",
    "\n",
    "if loglog:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "ax.set_xlim(450,max(data[\"M\"])*0.7) #min UMI is 500\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=18, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues%s_mca%s.pdf\"%(\"\" if filter_mammaryLactation else \"_noLactation\",\"_loglog\" if loglog else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "ax.hist(data[\"M\"], density=True, color=\"gray\", histtype=\"step\", lw=15, bins=50)\n",
    "\n",
    "m = np.mean(data[\"M\"])\n",
    "ax.vlines([m], 0,2e-8, lw=10, alpha=.9, ls=\"-.\")\n",
    "ax.annotate(\"Average: %.2e\"%m, (m*1.1,2e-8), fontsize=35)\n",
    "\n",
    "ax.set_xlabel(\"UMI per cell, $M$\", fontsize=35)\n",
    "ax.set_ylabel(\"Probability density function\", fontsize=35)\n",
    "\n",
    "#ax.set_xscale(\"log\")\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "#ax.set_xlim(1,3e8)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"M_hist_{data_source}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "for tissue in data[\"frac_of\"].keys():\n",
    "    try:\n",
    "        info = load_tissue(tissue)\n",
    "    except:\n",
    "        continue\n",
    "    M = info[\"M\"]\n",
    "    diff= info[\"diffWords\"]\n",
    "    x = M\n",
    "    y = diff\n",
    "    ax.plot(x, y, marker='o', lw=0, ms=10, alpha=0.6, label=tissue)\n",
    "    #ax.errorbar(x,y , bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "\n",
    "    \n",
    "ax.set_xlabel(\"Realization size\", fontsize=24)\n",
    "ax.set_ylabel(\"#different words\", fontsize=24)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlim(0,max(data[\"M\"])*0.7)\n",
    "    \n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=18, ncol=2)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues_alldata.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "M = data[\"M\"]\n",
    "diff= data[\"diffWords\"]\n",
    "x = M\n",
    "y = diff\n",
    "ax.plot(x, y, marker='o', lw=0, ms=10, alpha=0.6, label=tissue)\n",
    "#ax.errorbar(x,y , bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "#scatterdense(x,y, ax= ax)\n",
    "    \n",
    "\n",
    "ax.set_xlabel(\"Realization size\", fontsize=24)\n",
    "ax.set_ylabel(\"#different words\", fontsize=24)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlim(0,max(data[\"M\"])*0.7)\n",
    "    \n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def heaps_taylor(X, k):\n",
    "    return k * np.power(X, 2)\n",
    "\n",
    "def heaps_free_exponent(X, C, k):\n",
    "    return C * np.power(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog = True\n",
    "filter_mammaryLactation = True\n",
    "\n",
    "exps = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(36,15))\n",
    "for tissue in data[\"frac_of\"].keys():\n",
    "#for tissue in common_organs:\n",
    "    try:\n",
    "        info = load_tissue(tissue)\n",
    "    except:\n",
    "        continue\n",
    "    if (\"Lactation\" in tissue) and filter_mammaryLactation:\n",
    "        continue\n",
    "    #data = load_all_data(\"mca\")\n",
    "    M = info[\"M\"]\n",
    "    diff= info[\"diffWords\"]\n",
    "    n_bins=25\n",
    "\n",
    "    bins = np.logspace(np.log10(M.min()),np.log10(M.max()), n_bins)\n",
    "    #bins = np.linspace(M.min(),max(M), n_bins)\n",
    "    #bins = np.quantile(M,np.linspace(0,1, n_bins))\n",
    "\n",
    "\n",
    "\n",
    "    bin_means, bin_edges, binnumber = stats.binned_statistic(M, diff,statistic='mean', bins=bins)\n",
    "    bin_stds, _, _ = stats.binned_statistic(M, diff,statistic='std', bins=bins)\n",
    "    bin_counts, _, _ = stats.binned_statistic(M, diff,statistic='count', bins=bins)\n",
    "\n",
    "    bin_stds = np.power(bin_stds,2)\n",
    "\n",
    "    mask = bin_counts > 1e2\n",
    "    \n",
    "    x = bin_means[mask]\n",
    "    y = bin_stds[mask]\n",
    "    popt = [1]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(heaps_free_exponent, x,y)\n",
    "        print(tissue, *popt)\n",
    "        exps.append(popt[1])\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "        print(tissue)\n",
    "    finally:\n",
    "        ax.plot(x, y, marker='o', lw=5, ms=25, alpha=0.6, c=get_color(tissue))\n",
    "\n",
    "x = np.linspace(100,5e3)\n",
    "ax.plot(x,x, lw=15,ls=\"--\", c=\"blue\", label=\"Poisson\")\n",
    "ax.plot(x,x*x, lw =15, ls=\"--\", c=\"red\", label=\"Taylor\")\n",
    "ax.set_xlabel(\"Mean number of expressed genes\", fontsize=35)\n",
    "ax.set_ylabel(\"Variance number of expressed genes\", fontsize=35)\n",
    "\n",
    "ax.set_xlim(200,5e3) #min UMI is 500\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(fontsize=35, ncol=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues%s_mca%s_fluctuaction.pdf\"%(\"\" if filter_mammaryLactation else \"_noLactation\",\"_loglog\" if loglog else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(36,15))\n",
    "\n",
    "n_bins = 10\n",
    "bins = np.linspace(0-5/2/n_bins,5+5/2/n_bins,n_bins+2)\n",
    "ax.hist(exps, histtype=\"step\", density=True, color=\"gray\", lw=15, bins=bins)\n",
    "\n",
    "ax.set_xlabel(\"Fit's exponent\", fontsize=35)\n",
    "ax.set_ylabel(\"pdf\", fontsize=35)\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues%s_mca%s_fluctuaction_exponent_hist.pdf\"%(\"\" if filter_mammaryLactation else \"_noLactation\",\"_loglog\" if loglog else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog = True\n",
    "filter_mammaryLactation = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "info = load_all_data(\"mca\")\n",
    "M = info[\"M\"]\n",
    "diff= info[\"diffWords\"]\n",
    "n_bins=35\n",
    "\n",
    "bins = np.logspace(np.log10(M.min()),np.log10(M.max()), n_bins)\n",
    "#bins = np.linspace(M.min(),max(M), n_bins)\n",
    "#bins = np.quantile(M,np.linspace(0,1, n_bins))\n",
    "\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(M, diff,statistic='median', bins=bins)\n",
    "bin_stds, _, _ = stats.binned_statistic(M, diff,statistic='std', bins=bins)\n",
    "bin_counts, _, _ = stats.binned_statistic(M, diff,statistic='count', bins=bins)\n",
    "\n",
    "strong_mask = bin_counts > 5e3\n",
    "mask = bin_counts > 1e2\n",
    "\n",
    "bin_stds = np.power(bin_stds,2)\n",
    "\n",
    "x = bin_means\n",
    "y = bin_stds\n",
    "\n",
    "popt, pcov = curve_fit(heapsvar, x[strong_mask], y[strong_mask])\n",
    "print(*popt)\n",
    "print(pcov)\n",
    "\n",
    "ax.plot(x[strong_mask], y[strong_mask], marker='o', lw=15, ms=35, alpha=0.6, c=\"gray\")\n",
    "ax.plot(x[strong_mask], heapsvar(x[strong_mask], *popt), lw=8, ms=25, alpha=0.8, c=\"red\", label=\"Taylor times constant fit\")\n",
    "\n",
    "#ax.errorbar(x,y , bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "\n",
    "#popt, pcov = curve_fit(lambda x, C: C*x, x[(~strong_mask)*mask], y[(~strong_mask)*mask])\n",
    "#print(*popt)\n",
    "#print(pcov)\n",
    "#ax.plot(x[~strong_mask*mask], popt[0]*x[~strong_mask*mask], lw=8, ms=25, alpha=0.8, c=\"blue\")\n",
    "\n",
    "\n",
    "ax.plot(x,x, lw=15,ls=\"--\", c=\"blue\", label=\"Poisson\")\n",
    "ax.plot(x,x*x, lw =15, ls=\"--\", c=\"red\", label=\"Taylor\")\n",
    "ax.set_xlabel(\"Mean number of expressed genes\", fontsize=35)\n",
    "ax.set_ylabel(\"Variance number of expressed genes\", fontsize=35)\n",
    "\n",
    "ax.set_xlim(300,2e3) #min UMI is 500\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=25)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(fontsize=35, ncol=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_alltissues%s_mca%s_fluctuaction_all.pdf\"%(\"\" if filter_mammaryLactation else \"_noLactation\",\"_loglog\" if loglog else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrals = pd.read_csv(\"integral_heaps.csv\", index_col=1)\n",
    "integrals=integrals.sort_values(\"data\", ascending=False)\n",
    "integrals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "for x,tissue in enumerate(integrals.index):\n",
    "    plt.plot(x, integrals.at[tissue,\"data\"], marker=\"P\", c=get_color(tissue), lw=0, ms=15)\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks(range(0,len(integrals.index)), labels = integrals.index, rotation=90)\n",
    "plt.ylabel(\"Heaps' integral\", fontsize=20)\n",
    "fig.savefig(\"itegral_heapfs_scatter_plot_color_mca.pdf\")\n",
    "fig.savefig(\"itegral_heapfs_scatter_plot_color_mca.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(o, M, gamma, N):\n",
    "    i = np.arange(1, N+1, step=1)\n",
    "    alpha_i = i**(-gamma)\n",
    "    alpha = np.sum(alpha_i, axis=0)\n",
    "    p_num = (1-o)**(1/M-1)\n",
    "    K = (1-(1-o)**(1/M))**(1+1/gamma)\n",
    "    p_den = gamma*M*N*(alpha**(1/gamma))*K\n",
    "    return p_num/p_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "rang = (0-0.5/nbins, 1+0.5/nbins)\n",
    "\n",
    "bins = np.logspace(np.log10(1e-2),np.log10(rang[1]),num=nbins)\n",
    "#bins = np.linspace(rang[0], rang[1], num=nbins)\n",
    "\n",
    "fig, ax =plt.subplots(figsize=(18,15))\n",
    "ax.hist(np.array(O, dtype=float), histtype='step', lw=15, color='gray', density=True, bins=bins)\n",
    "if \"O_null\" in vars().keys():\n",
    "    ax.hist(np.array(O_null, dtype=float), histtype='step', lw=15, bins=bins, color='red', ls='--', density=True)\n",
    "ax.set_xlabel(\"Occurrence, $o_i$\", fontsize=35)\n",
    "ax.set_ylabel(\"Probability Density Function\", fontsize=35)\n",
    "\n",
    "x_bins=np.arange(1e-2,rang[1],step=(rang[1]-rang[0])/nbins)\n",
    "ax.plot(x_bins,[p(x, M.mean(), 0.8, len(O)) for x in x_bins], lw=15, ls=\"--\", c=\"orange\")\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.set_xlim(9e-3,1.5)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.show()\n",
    "fig.savefig(f\"U_{data_source}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(M, density=False, color='blue', bins = 15, label='files')\n",
    "#plt.hist(M_null, density=False, color='orange', histtype='step', lw=4, ls='--', bins = 15, label='files')\n",
    "plt.title(\"realization size distribution\", fontsize = 24)\n",
    "plt.xlabel(\"total counts per file\", fontsize=24)\n",
    "plt.ylabel(\"#\", fontsize=24)\n",
    "plt.legend(fontsize=24)\n",
    "plt.show()\n",
    "fig.savefig(\"M_distr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(diffWords, density=False, color='blue', bins = 15, label = 'files')\n",
    "plt.title(\"vocabulary size distribution\", fontsize=18)\n",
    "plt.xlabel(\"#different words per file\", fontsize=16)\n",
    "plt.ylabel(\"#\", fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()\n",
    "fig.savefig(\"gene_expr_distr.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(m, gamma, N):\n",
    "    i = np.arange(1, N+1, step=1)\n",
    "    alpha_i = i**(-gamma)\n",
    "    alpha = np.sum(alpha_i, axis=0)\n",
    "    return N - np.sum((1-np.power(i, -gamma)/alpha)**m, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "\n",
    "ax.scatter(data[\"M\"], data[\"diffWords\"], label='samples', alpha=0.5, s=225, c=\"gray\")\n",
    "if \"M_null\" in vars().keys() and \"diffWords_null\" in vars().keys():\n",
    "    plt.scatter(M_null, diffWords_null, label='null_model', s=225, c=\"red\")\n",
    "ax.set_ylabel(\"Number of genes expressed\", fontsize=35)\n",
    "ax.set_xlabel(\"UMI per cell\", fontsize=35)\n",
    "skip_bins = 2\n",
    "n_bins=15\n",
    "\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(data[\"M\"], data[\"diffWords\"],statistic='mean', bins=np.logspace(np.log10(data[\"M\"].min()),np.log10(max(data[\"M\"])), n_bins))\n",
    "#ax.hlines(bin_means[:-skip_bins], bin_edges[:-1][:-skip_bins], bin_edges[1:][:-skip_bins], colors='r', lw=5, label='binned average')\n",
    "#bin_stds, _, _ = stats.binned_statistic(data[\"M\"], data[\"diffWords\"],statistic='std', bins=np.linspace(M.min(),np.quantile(M, 0.9), n_bins))\n",
    "#ax.errorbar(((bin_edges[:-1]+bin_edges[1:])/2)[:-skip_bins],bin_means[:-skip_bins], bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "\n",
    "ax.plot((bin_edges[:-1][:-skip_bins] + bin_edges[1:][:-skip_bins])/2, bin_means[:-skip_bins], color='blue', lw=10, marker=\"o\", ms=25, label='binned average')\n",
    "\n",
    "\n",
    "x_bins=np.logspace(np.log10(data[\"M\"].min()),np.log10(max(data[\"M\"])))\n",
    "ax.plot(x_bins, [h(x, 0.8, len(data[\"freq\"].dropna())) for x in x_bins], lw=15, ls=\"--\", c=\"orange\", label=\"model\")\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(450,max(M)*1.1)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.legend(fontsize=35)\n",
    "plt.show()\n",
    "fig.savefig(\"heaps.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_func = lambda x, a, b: a + np.power(x, b)\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "bin_vars = bin_stds*bin_stds\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(bin_means[:-skip_bins], bin_vars[:-skip_bins],s=90, label='')\n",
    "ax.plot(bin_means[:-skip_bins], bin_means[:-skip_bins], label='Poisson')\n",
    "ax.plot(bin_means[:-skip_bins], bin_means[:-skip_bins]**2, label='Taylor')\n",
    "\n",
    "popt, pcov = curve_fit(fit_func, bin_means[:-skip_bins], bin_vars[:-skip_bins])\n",
    "ax.plot(bin_means[:-skip_bins], fit_func(bin_means[:-skip_bins], *popt), label=\"%.0f + x**%.1f\"%(popt[0],popt[1]))\n",
    "\n",
    "ax.set_xlabel(\"Heaps' mean\", fontsize=24)\n",
    "ax.set_ylabel(\"Heaps' var\", fontsize=24)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=24)\n",
    "#ax.set_ylim(1e3,3e4)\n",
    "ax.set_xlim(np.nanmin(bin_means),np.nanmax(bin_means))\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_Taylor.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_bins = lambda x, a, b: a + np.power(x,b)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.scatter(data[\"M\"], diffWords, label='samples')\n",
    "plt.xlabel(\"Realization size\", fontsize=24)\n",
    "plt.ylabel(\"#different words\", fontsize=24)\n",
    "n_bins=35\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(data[\"M\"], diffWords,statistic='mean', bins=np.linspace(data[\"M\"].min(),max(data[\"M\"]), n_bins))\n",
    "bin_counts, bin_edges, binnumber = stats.binned_statistic(data[\"M\"], diffWords,statistic='count', bins=np.linspace(data[\"M\"].min(),max(data[\"M\"]), n_bins))\n",
    "\n",
    "skip_bins=(bin_counts<10).astype(int).sum()\n",
    "x_bins = ((bin_edges[:-1]+bin_edges[1:])/2)[:-skip_bins]\n",
    "\n",
    "plt.hlines(bin_means[:-skip_bins], bin_edges[:-1][:-skip_bins], bin_edges[1:][:-skip_bins], colors='r', lw=5, label='binned average')\n",
    "bin_stds, _, _ = stats.binned_statistic(data[\"M\"], diffWords,statistic='std', bins=np.linspace(M.min(),np.quantile(M, 0.9), n_bins))\n",
    "plt.errorbar(x_bins,bin_means[:-skip_bins], bin_stds[:-skip_bins], fmt='none', ecolor='orange', elinewidth=3)\n",
    "\n",
    "popt, pcov = curve_fit(fit_bins, x_bins, bin_means[:-skip_bins])\n",
    "\n",
    "plt.plot(np.linspace(500, 2e4), fit_bins(np.linspace(500, 2e4), *popt), lw=4, c='cyan')\n",
    "\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlim(0,max(data[\"M\"])*1.1)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"heaps.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = data[\"var\"].dropna()\n",
    "means = data[\"means\"].dropna()\n",
    "O = data[\"O\"].dropna()\n",
    "O = O[~O.duplicated()]\n",
    "means = means[~means.duplicated()]\n",
    "var = var[~var.duplicated()]\n",
    "means = means[var[var>1e-7].index].dropna()\n",
    "var = var.reindex_like(means)\n",
    "O = O.reindex_like(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes=pd.read_csv(\"genes_gtex.txt\", header=0, index_col=0)\n",
    "df_genes.head()\n",
    "nc=df_genes[df_genes[\"type_of_gene\"]!=\"protein-coding\"].index\n",
    "pc=df_genes[df_genes[\"type_of_gene\"]==\"protein-coding\"].index\n",
    "genelist = pd.read_csv(\"https://stephenslab.github.io/count-clustering/project/utilities/gene_names_all_gtex.txt\", header=None).values.ravel()\n",
    "pc=pc[pc.isin(genelist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select protein coding or noncoding\n",
    "means = means[means.index.isin(pc)]\n",
    "var = var.reindex_like(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "ax.set_xlim(1e-3, 5e2)\n",
    "\n",
    "plotcv2mean(means.values.ravel(), var.values.ravel(), ax=ax, normalisation_str='counts', poisson_limit=1, alpha=0.5, s=255, colorbar=True)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", width=5, length=10)\n",
    "\n",
    "upbound = len(data[\"M\"])-1\n",
    "x = np.logspace(-5,7)\n",
    "ax.plot(x,[upbound for _ in x], ls=\"--\", lw=15, c=\"orange\", label=\"R-1\")\n",
    "\n",
    "ax.legend(fontsize=30)\n",
    "ax.set_ylim(5e-1,5e5)\n",
    "plt.show()\n",
    "fig.savefig(f\"cv2_mean_dense_{data_source}.pdf\")\n",
    "fig.savefig(f\"cv2_mean_dense_{data_source}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "#plt.scatter(means, var, c='gray', alpha=0.3, s=80, label='genes')\n",
    "plotvarmen(means.values, var.values, ax=ax, alpha=0.5, s=255, colorbar=True)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.set_ylim(1e-6,np.power(10,np.log10(var.max())+1))\n",
    "ax.set_xlim(1e-5,max(means)*1.5)\n",
    "ax.legend(fontsize=35)\n",
    "plt.show()\n",
    "fig.savefig(f\"var_mean_dense_{data_source}.pdf\")\n",
    "fig.savefig(f\"var_mean_dense_{data_source}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single cell zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mca/mainTable_Bone-Marrow_c-kit.csv\", header=0, index_col=0)\n",
    "M = df.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = M.sort_values(ascending=False).index[:100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"top100_cells_bm.npy\", df[df.columns[df.columns.isin(top100)]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "df[df.columns[df.columns.isin(top100)]].apply(lambda x: ax.plot((x.sort_values(ascending=False)/x.sum()).values), axis=0)\n",
    "\n",
    "x =np.linspace(1,6e3,10)\n",
    "\n",
    "exp = 0.8\n",
    "ax.plot(x, 1e-1*np.power(x, -0.8), lw=20, c='gray', ls='--')\n",
    "ax.annotate('$k*i^{-%.1f}$'%exp, (1e2,1e-2), fontsize=35)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"$Frequency, f_i$\", fontsize=35)\n",
    "ax.set_xlabel(\"$RANK, i$\", fontsize=35)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", width=5, length=15)\n",
    "\n",
    "\n",
    "ax.set_xlim(1,2e4)\n",
    "ax.set_ylim(6e-5,1e-1)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"zipf_top100_mca.pdf\")\n",
    "fig.savefig(\"zipf_top100_mca.png\", dpi=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean vs Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,8))\n",
    "nfiles = len(data[\"M\"])\n",
    "plt.scatter(O*nfiles, means, c='b', alpha=0.8, label='genes')\n",
    "#plt.scatter(O_null*len(M_null), means_null*5, c='orange', alpha=0.8, label='genes')\n",
    "\n",
    "x = np.linspace(1,nfiles)\n",
    "plt.plot(x, x/(nfiles), lw=4, label='bound', c='cyan', ls='--')\n",
    "\n",
    "\n",
    "bin_means, bin_edges, _ = stats.binned_statistic(O*nfiles, means, statistic='mean', bins=np.logspace(-3,6))\n",
    "x = (bin_edges[1:]+bin_edges[:-1])/2\n",
    "plt.scatter(x,bin_means, marker='x', c='r', label='binned average')\n",
    "plt.ylabel(\"$<counts>$\", fontsize=16)\n",
    "plt.xlabel(\"$\\Sigma_j\\Theta(counts)$\", fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(means[means!=0].min()/5,np.power(10,np.log10(means.max())+1))\n",
    "plt.xlim(5e-1,nfiles+8000)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"mean_occ.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "nfiles = len(data[\"M\"])\n",
    "means_nozero = means_nozero.dropna()\n",
    "x_data = O.reindex_like(means_nozero)*nfiles\n",
    "\n",
    "plt.scatter(x_data, means_nozero, c='b', alpha=0.8, label='genes')\n",
    "\n",
    "bin_means, bin_edges, _ = stats.binned_statistic(x_data, means_nozero, statistic='mean', bins=np.logspace(0,5,30))\n",
    "x = (bin_edges[1:]+bin_edges[:-1])/2.\n",
    "plt.scatter(x,bin_means, marker='x', c='r', label='binned average')\n",
    "\n",
    "bin_mins, _, _ = stats.binned_statistic(x_data, means_nozero, statistic='min', bins=np.logspace(0,5,30))\n",
    "#f = lambda x, a, b, c, d:np.exp(-a*x) + b*x + c + d*x*x\n",
    "#f = lambda x, a, C: C + np.power(a, -x)\n",
    "\n",
    "#popt, pcov = curve_fit(f, x[2:], bin_mins[2:] )\n",
    "#plt.scatter(x,bin_mins, marker='x', c='g', label='bound')\n",
    "#plt.plot(x,f(x, *popt), c='g', label='bound')\n",
    "\n",
    "\n",
    "plt.ylabel(\"$<counts(>0)>$\", fontsize=16)\n",
    "plt.xlabel(\"$\\Sigma_j\\Theta(counts)$\", fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(0.5,np.power(10,np.log10(means.max())+1))\n",
    "plt.xlim(5e-1,nfiles+10000)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"mean_occ_non_zero.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M vs N_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x_data = M\n",
    "y_data = cell_zeros/len(A)\n",
    "\n",
    "plt.scatter(x_data, y_data, label='cell')\n",
    "bin_means, bin_edges, _ = stats.binned_statistic(x_data, y_data, statistic='mean', bins=np.linspace(0,8000,10))\n",
    "x = ((bin_edges[1:]+bin_edges[:-1])/2.)[~np.isnan(bin_means)]\n",
    "bin_means = bin_means[~np.isnan(bin_means)]\n",
    "plt.scatter(x,bin_means, marker='x', c='r', label='binned average')\n",
    "\n",
    "fit_func = lambda x, a, C: C + a*x\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(fit_func, x, bin_means )\n",
    "plt.plot(x,fit_func(x, *popt), c='g', ls='--', label='fit (%.10f x + %.3f)'%(popt[0], popt[1]))\n",
    "\n",
    "plt.xlabel(\"M\")\n",
    "plt.ylabel(\"#zeri/#geni\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x_data = M\n",
    "y_data = np.log10(cell_zeros/len(A))\n",
    "\n",
    "plt.scatter(x_data, y_data, label='cell')\n",
    "bin_means, bin_edges, _ = stats.binned_statistic(x_data, y_data, statistic='mean', bins=np.linspace(0,4000,10))\n",
    "x = ((bin_edges[1:]+bin_edges[:-1])/2.)[~np.isnan(bin_means)]\n",
    "bin_means = bin_means[~np.isnan(bin_means)]\n",
    "plt.scatter(x,bin_means, marker='x', c='r', label='binned average')\n",
    "\n",
    "fit_func = lambda x, a, C: C + a*x\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(fit_func, x, bin_means )\n",
    "plt.plot(x,fit_func(x, *popt), c='g', ls='--', label='fit (%.5f x + %.3f)'%(popt[0], popt[1]))\n",
    "\n",
    "plt.xlabel(\"M\")\n",
    "plt.ylabel(\"log(#zeri/#geni)|M\")\n",
    "plt.xlim(0,8000)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x_data = M\n",
    "y_data =cell_zeros/len(A)\n",
    "\n",
    "plt.scatter(x_data, np.log2(y_data), label='cell')\n",
    "bin_means, bin_edges, _ = stats.binned_statistic(x_data, y_data, statistic='mean', bins=np.linspace(0,4000,10))\n",
    "x = ((bin_edges[1:]+bin_edges[:-1])/2.)[~np.isnan(bin_means)]\n",
    "bin_means = bin_means[~np.isnan(bin_means)]\n",
    "plt.scatter(x,np.log2(bin_means), marker='x', c='r', label='binned average')\n",
    "\n",
    "fit_func = lambda x, a, C: C + a*x\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(fit_func, x, bin_means )\n",
    "plt.plot(x,np.log2(fit_func(x, *popt)), c='g', ls='--', label='fit (%.5f x + %.3f)'%(popt[0], popt[1]))\n",
    "\n",
    "plt.xlabel(\"M\")\n",
    "plt.ylabel(\"log(#zeri/#geni|M)\")\n",
    "\n",
    "plt.xlim(0,8000)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P(0|M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p0m(df, M, limits = (100,110)):\n",
    "    M_sorted = M.sort_values(ascending=True)\n",
    "    quantiles = np.quantile(M, q=np.linspace(0,1,10)[:-1])\n",
    "    #quantiles = np.linspace(M.min(), M.max(), 20)\n",
    "    M_classes = pd.Series(index=M.index, data=np.digitize(M, quantiles))\n",
    "    f = df.mean(1)\n",
    "    f = f/f.sum()\n",
    "    f_ = df.apply(lambda x: x[x>0].mean(), 1)\n",
    "    f_ = f_/f_.sum()\n",
    "    ret = {}\n",
    "    for g in f.sort_values(ascending=False).index[limits[0]:limits[1]]:\n",
    "        genexpr = df.loc[g,:]\n",
    "        ret[g] =  [(genexpr[M_classes[M_classes==c].index]==0).astype(int).sum()/len(M_classes[M_classes==c]) for c in np.arange(len(quantiles))+1]\n",
    "        del genexpr\n",
    "        gc.collect()\n",
    "    return ret, quantiles, (f.sort_values(ascending=False)[limits[0]:limits[1]].mean(), f_.sort_values(ascending=False)[limits[0]:limits[1]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import json\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "palette = itertools.cycle(sns.color_palette(palette=\"Set1\", n_colors=100, desat=.9))\n",
    "\n",
    "def markers():\n",
    "    for m in ['x', 'o', '.', ',', 'v', '>', '<', '1', '2', '3', '4', '5', '6', '7', '8', '9']:\n",
    "        yield m\n",
    "\n",
    "subdf = pd.read_csv(\"mca/mainTable_Stomach.csv\", index_col=0)\n",
    "M = subdf.sum(0)\n",
    "results = pd.DataFrame(columns=[\"rank\", \"a\", \"b\", \"f\", \"f_\"])\n",
    "for under_limit in np.linspace(100, 2e4, num=25, dtype=int):\n",
    "    print(under_limit)\n",
    "    color = next(palette)\n",
    "    markers_cycle = markers()\n",
    "    p0mdata, M_bins, F = p0m(subdf, M, limits=(under_limit,under_limit+5))\n",
    "    tmp = []\n",
    "    for g in p0mdata.keys():\n",
    "        tmp.append(p0mdata[g])\n",
    "        plt.plot(M_bins, p0mdata[g], label=g, c=color, marker = next(markers_cycle))\n",
    "    tmp=np.average(tmp, 0)\n",
    "    try:\n",
    "        popt, pcov = curve_fit(lambda x, a, b: a - b*x, M_bins, tmp)\n",
    "        results = results.append(pd.Series(name=under_limit, data=[under_limit, popt[0], popt[1], json.dumps(pcov.tolist()), F[0], F[1]], index=[\"rank\", \"a\", \"b\", \"cov\", \"f\", \"f_\"]))\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "del subdf\n",
    "del M\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel(\"M\", fontsize=24)\n",
    "plt.ylabel(\"P(0|M)\")\n",
    "\n",
    "plt.ylim(5e-4,1)\n",
    "\n",
    "#plt.legend(ncol=3)\n",
    "fig.savefig(\"logpm.pdf\")\n",
    "fig.savefig(\"logpm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_covariance_element():\n",
    "    for result in results[\"cov\"].values:\n",
    "        pcov = np.array(json.loads(result))\n",
    "        yield pcov\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "\n",
    "ax.scatter(results[\"f\"], results[\"b\"], c=\"gray\", alpha=0.5, ls='--', s = 50**2)\n",
    "\n",
    "sigma_generator = unpack_covariance_element()\n",
    "ax.errorbar(results[\"f\"], results[\"b\"], yerr=[np.sqrt(pcov[1,1]) for pcov in sigma_generator], fmt=\"\", lw=0, elinewidth=15)\n",
    "\n",
    "ax.plot(results[\"f\"], results[\"f\"], ls='--', lw=20)\n",
    "\n",
    "ax.set_xlim(results[\"f\"].min()*0.8, results[\"f\"].max()*1.5)\n",
    "ax.set_ylim(results[\"b\"].min()*0.8, results[\"b\"].max()*1.5)\n",
    "\n",
    "ax.set_xlabel(\"f\", fontsize=35)\n",
    "ax.set_ylabel(\"b\", fontsize=35)\n",
    "\n",
    "ax.set_xlim(results[\"f\"][results[\"f\"]>0].min()/10, results[\"f\"].max()*10)\n",
    "ax.set_ylim(results[\"b\"][results[\"b\"]>0].min()/10, results[\"b\"].max()*10)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.0E'))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0E'))\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", width=5, length=10)\n",
    "\n",
    "ax.set_title('Correlation: %.3f'%(pearsonr(results[\"f\"],results[\"b\"])[0]), fontsize=35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"p0m_fbrelationship.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "subdf = pd.read_csv(\"mca/mainTable_Bladder.csv\", index_col=0).sample(1000)\n",
    "print(subdf.info())\n",
    "M = subdf.sum(0)\n",
    "M_sorted = M.sort_values(ascending=True)\n",
    "quantiles = np.quantile(M, q=np.linspace(0,1,10)[:-1])\n",
    "#quantiles = np.linspace(M.min(), M.max(), 20)\n",
    "M_classes = pd.Series(index=M.index, data=np.digitize(M, quantiles))\n",
    "\n",
    "def extrapolate_b(genexpr):\n",
    "    tmp = np.array([(genexpr[M_classes[M_classes==c].index]==0).astype(int).sum()/len(M_classes[M_classes==c]) for c in np.arange(len(quantiles))+1])\n",
    "    tmp[np.isnan(tmp)]=0\n",
    "    popt, pcov = curve_fit(lambda x, a, b: a - b*x, quantiles, tmp)\n",
    "    del tmp\n",
    "    return popt[1]\n",
    "bs = subdf.apply(extrapolate_b, 1)\n",
    "fs = subdf.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "thr = 2e-1\n",
    "ax.scatter(fs[fs<thr],bs[fs<thr], c=\"gray\", alpha=0.5, ls='--', s = 200)\n",
    "\n",
    "#ax.set_xlim(fs[fs>0].min()*0.8, fs[fs<np.inf].max()*1.5)\n",
    "#ax.set_ylim(bs[bs!=0].min()*0.8, bs[bs<np.inf].max()*1.5)\n",
    "\n",
    "ax.set_xlabel(\"f\", fontsize=35)\n",
    "ax.set_ylabel(\"b\", fontsize=35)\n",
    "\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.0E'))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0E'))\n",
    "\n",
    "#ax.set_xscale('log')\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", width=5, length=10)\n",
    "\n",
    "ax.set_title('Correlation: %.3f'%(pearsonr(fs[fs<thr],bs[fs<thr])[0]), fontsize=35)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"p0m_allgenes.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = \"Kidney\"\n",
    "df = pd.read_csv(f\"mca/mainTable_{tissue}.csv\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df.sum(axis=0)\n",
    "M=M.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.quantile(M[M<4000].values, q=np.linspace(0,1,11))[:-1]\n",
    "#idxs = np.linspace(500,M.max(),num=20)\n",
    "\n",
    "sizes = {}\n",
    "thetas_c = [0.8,0.85,0.9,0.95,0.99]\n",
    "for theta in thetas_c:\n",
    "    sizes[\"%.2f\"%theta] = []\n",
    "\n",
    "\n",
    "#for (m_, m) in zip(M[idxs].index[:-1], M[idxs].index[1:]):\n",
    "for (m_,m) in zip(quantiles[:-1], quantiles[1:]):\n",
    "    print(f\"[{m_},{m})\")\n",
    "    O = df.reindex(columns=M[(m_<=M)&(M<m)].index).dropna(how=\"any\", axis=1).apply(lambda g: len(g[g>0])/float(len(g)), axis=1)\n",
    "    for theta in thetas_c:\n",
    "        sizes[\"%.2f\"%theta].append(len(O[O>theta])/len(O))\n",
    "    del O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_means = (quantiles[1:]+quantiles[:-1])/2.\n",
    "#q_means = (M[idxs].index[1:]+M[idxs].index[:-1])/2.\n",
    "\n",
    "M_bin=q_means\n",
    "\n",
    "N=df.shape[0]\n",
    "\n",
    "def fit_teo(X_data, gamma, thetac, N=df.dropna(how=\"all\", axis=1).shape[0]):\n",
    "    \"\"\"\n",
    "    - gamma: Zipf exponent\n",
    "    - theta_c: Occurrences thresholds\n",
    "    \"\"\"\n",
    "    M_bin = X_data\n",
    "    \n",
    "    i = np.arange(1,N+1, step=1)\n",
    "    alpha_i=i**(-gamma)\n",
    "    alpha=np.sum(alpha_i, axis=0)\n",
    "    # predicted core size \n",
    "\n",
    "    k=M_bin**(1/gamma)/(alpha**(1/gamma)*N)\n",
    "    c=k*(-np.log(1-thetac))**(-1/gamma)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "fig,ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "for (threshold,sizes_arr), color in zip(sizes.items(),[\"blue\", \"gray\", \"red\", \"orange\", \"green\"]):\n",
    "    ax.plot(q_means, sizes_arr, lw=10, marker=\"o\", ms=45, c=color, label=f\"data\")\n",
    "    popt = [0.8, float(threshold)]\n",
    "    ax.plot(q_means, fit_teo(q_means, *popt), c=\"dark\"+color, lw=15, ls=\"--\", label=\"predicted ($\\\\theta_c$=%.2f)\"%(popt[1]), alpha=0.7)\n",
    "\n",
    "threshold = 0.9\n",
    "#ax.plot(q_means, sizes[\"0.9\"], lw=15, marker=\"o\", ms=30, c=\"gray\", label=f\"data with thr={threshold}\")\n",
    "\n",
    "\n",
    "#popt, pcov = curve_fit(fit_teo, q_means, sizes[\"0.9\"], p0=[0.8, 0.95])\n",
    "popt = [0.8, 0.9]\n",
    "#ax.plot(q_means, fit_teo(q_means, *popt), lw=15, ls=\"--\", label=\"predicted (gamma=%.2f; thetac=%.2f)\"%(popt[0],popt[1]), alpha=0.8, c=\"orange\")\n",
    "\n",
    "ax.set_ylim(0,0.005)\n",
    "\n",
    "ax.set_ylabel(\"Core size\", fontsize=45)\n",
    "ax.set_xlabel(\"Total reads per cell, $M$\", fontsize=45)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.legend(ncol=2,fontsize=30)\n",
    "plt.show()\n",
    "fig.savefig(f\"U_core_prediction_{tissue}_allthr.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[M.index]\n",
    "A = df.sum(1)\n",
    "f = A.sort_values(ascending=False)\n",
    "#df=df[df.index.isin(f[49:4500].index)]\n",
    "#save_model(df,tissue=\"bonemarrow_M100\",name=\"data\", n_bins=15)\n",
    "#mazzolini(np.repeat(M.mean(), len(M)), A/A.sum(), \"bonemarrow_M_avg\", n_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(18,15))\n",
    "x = np.arange(1, len(f))\n",
    "ax.set_ylabel(\"$Frequency, f_i$\", fontsize=35)\n",
    "ax.set_xlabel(\"$RANK, i$\", fontsize=35)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "#plt.ylim(1e-7,1)\n",
    "ax.plot(x, np.power(x,-0.8)*1e-1, 'g--', lw=10, label='$k*i^{-0.8}$')\n",
    "ax.plot(np.sort(f.dropna())[::-1]/f.sum(), c='blue', lw=15, label='Genes')\n",
    "if \"f_null\" in vars().keys():\n",
    "    ax.plot(np.sort(f_null/f_null.sum())[::-1], c='orange', ls='--', lw=15, label='null_model')\n",
    "    \n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.legend(fontsize=35)\n",
    "plt.show()\n",
    "fig.savefig(\"zipf.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tissue = \"all\"\n",
    "#data = load_all_data()\n",
    "tissue = \"Bone-Marrow_c-kit\"\n",
    "data = load_tissue(tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = data[\"freq\"].values\n",
    "M = data[\"M\"].values\n",
    "O = data[\"O\"].values\n",
    "R = M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_real = np.array([])\n",
    "O_pred = np.array([])\n",
    "O_pred_ds = np.array([])\n",
    "\n",
    "\n",
    "step = 1500\n",
    "for start in range(0,len(O),step):\n",
    "    print(start)\n",
    "    mask = np.repeat(False, len(O))\n",
    "    mask[start:start+step]=True\n",
    "\n",
    "    O_real = np.concatenate([O_real,O[mask]])\n",
    "    O_pred = np.concatenate([O_pred,list(map(lambda p: 1-1/R*np.sum(np.exp(-p*M)),P[mask]))])\n",
    "    \n",
    "genes = data[\"freq\"].index[O_real < (0.8*O_pred)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data[\"freq\"]\n",
    "\n",
    "pos_mask = (~f.isna()) & (f>0)\n",
    "\n",
    "g_high = f.index[O_pred > O_real + 0.2].values\n",
    "g_low = f.index[O_pred < O_real * 0.6 - 0.03].values\n",
    "\n",
    "#mask_high = (f.index.isin(g_high)) & (pos_mask)\n",
    "#mask_low = (f.index.isin(g_low)) & (pos_mask)\n",
    "#mask_nc = (f.index.isin(nc)) & (pos_mask)\n",
    "\n",
    "f_sorted = f[f>0].sort_values(ascending=False)\n",
    "mask_sorted_high = f_sorted.index.isin(g_high)\n",
    "mask_sorted_low = f_sorted.index.isin(g_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "nbins = 25\n",
    "rang = (0-0.5/nbins, 1+0.5/nbins)\n",
    "\n",
    "#bins = np.logspace(np.log10(1e-2),np.log10(rang[1]),num=nbins)\n",
    "bins=np.linspace(1e-4,rang[1],num=nbins)\n",
    "\n",
    "ax.hist(O, bins=bins, color = \"gray\", label=\"data\", density=True)\n",
    "\n",
    "O_pred_hist, bin_edges = np.histogram(O_pred, bins=bins, density=True)\n",
    "ax.plot((bin_edges[:-1]+bin_edges[1:])/2, O_pred_hist, ls='--', lw=10, c=\"red\", label=\"O_predicted\")\n",
    "#ax.hist(load_tissue(\"Bone-Marrow_c-kit\",name=\"mazzolini\")[\"O\"], histtype=\"step\", ls='--', bins=bins, density=True, color=\"orange\", lw=10, label=\"sampling\")\n",
    "\n",
    "ax.plot(bins,[p(x, M.mean(), 0.8, len(O)) for x in bins], lw=15, ls=\"--\", color=\"darkred\", label=\"teo_prediction <M>\")\n",
    "\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", width=5, length=10)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "#ax.set_xscale('log')\n",
    "\n",
    "ax.set_ylim(5e-4,1e2)\n",
    "\n",
    "ax.legend(fontsize=35)\n",
    "ax.set_xlabel(\"Occurrence, $O_i$\", fontsize=35)\n",
    "ax.set_ylabel(\"pdf\", fontsize=35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"U_{tissue}_sampling_pred.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "ax.scatter(O_real, O_pred, s=200, c='gray')\n",
    "ax.plot([0,1], [0,1], color = \"black\", ls='--', lw=15, alpha=0.9)\n",
    "\n",
    "ax.scatter(O_real[mask_high], O_pred[mask_high], s=200, c='b')\n",
    "#ax.scatter(O_real[mask_low], O_pred[mask_low], s=200, c='red')\n",
    "\n",
    "#ax.scatter(O_real[mask_nc], O_pred[mask_nc], s=200, c='red')\n",
    "#ax.scatter(O_pred, load_tissue(tissue, \"mazzolini\")[\"O\"], s=200, c='red')\n",
    "\n",
    "\n",
    "#ax.set_xlabel(\"$O_i$ from data\", fontsize=35)\n",
    "ax.set_xlabel(\"$O_i$ from from sampling\", fontsize=35)\n",
    "ax.set_ylabel(\"$O_i$ predicted\", fontsize=35)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", width=5, length=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"O_real-O_pred_{tissue}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"OrealOpred_overlist_{tissue}_low.txt\",\"w\") as f:\n",
    "    list(map(lambda g: f.write(g+\"\\n\"), filter(lambda g: \"Rik\" not in g, data[\"freq\"].index.values[mask_low])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "f_sorted.plot(ax=ax, color=\"gray\", lw=15, label=\"data\")\n",
    "\n",
    "for mask, label, color, marker in zip([mask_sorted_low, mask_sorted_high],\n",
    "                                      [\"genes under $O_i$ prediction\", \"genes over $O_i$ prediction\"],\n",
    "                                     [\"r\", \"b\"],\n",
    "                                     [\"o\",\"o\"]):\n",
    "    count = mask.sum()\n",
    "    ax.plot(np.arange(0,len(data[\"freq\"]),1)[mask], f_sorted[mask].sort_values(ascending=False), lw=0, ms=20, label=label + f\"({count})\", c=color, marker=marker, alpha = 0.4)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"$Frequency, f_i$\", fontsize=35)\n",
    "ax.set_xlabel(\"$RANK, i$\", fontsize=35)\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.legend(fontsize=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"mca/mainTable_{tissue}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_mat=df[df.index.isin(g_high)].transpose().applymap(lambda x: 1 if x > 0 else 0).corr()\n",
    "c_mat=df[df.index.isin(g_high)].transpose().applymap(lambda x: 1 if x > 0 else 0).corr(method = lambda x,y: np.abs(x-y).sum()/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(c_mat, vmin=0, vmax=1, xticklabels=g_high, yticklabels=g_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = df.sample(len(g_high), axis=0).append(df[df.index.isin(g_high)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.convert_to_tensor(subdf.applymap(lambda x: 1 if x > 0 else 0).values)\n",
    "start = time.time()\n",
    "corr_mat = tf.map_fn(lambda x: tf.map_fn(lambda y: tf.divide(tf.reduce_sum(tf.abs(x-y)), x.shape[0], tf.float32), data, dtype=tf.float64), data, dtype=tf.float64)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "c_mat = subdf.transpose().applymap(lambda x: 1 if x > 0 else 0).corr(method = lambda x,y: np.abs(x-y).sum()/len(x))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdf = df.sample(len(g_high), axis=0)\n",
    "#subdf = df[df.index.isin(g_high)]\n",
    "#c_mat = subdf.transpose().applymap(lambda x: 1 if x > 0 else 0).corr(method = lambda x,y: np.abs(x-y).sum()/len(x))\n",
    "#c_mat = subdf.transpose().applymap(lambda x: 1 if x > 0 else 0).corr()\n",
    "sns.heatmap(c_mat, vmin=0, vmax=1, xticklabels=subdf.index, yticklabels=subdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "x=data[\"means\"]\n",
    "ax.scatter(x,data[\"cv2\"])\n",
    "ax.scatter(x,data[\"mazzolini\"][\"cv2\"])\n",
    "ax.plot(x,1/x)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(m, gamma, N):\n",
    "    i = np.arange(1, N+1, step=1)\n",
    "    alpha_i = i**(-gamma)\n",
    "    alpha = np.sum(alpha_i, axis=0)\n",
    "    return N - np.sum((1-np.power(i, -gamma)/alpha)**m, axis=0)\n",
    "\n",
    "def h_double(m, gamma: list, N, F=122):\n",
    "    g1, g2 = gamma\n",
    "    i = np.arange(1, N+1, step=1)\n",
    "    alpha_i = [_i**(-g1) if _i < F else _i**(-g2) for _i in i]\n",
    "    alpha = np.sum(alpha_i, axis=0)\n",
    "    return N - np.sum((1-np.power(i[:F], -g1)/alpha)**m, axis=0) - np.sum((1-np.power(i[F:], -g2)/alpha)**m, axis=0)\n",
    "\n",
    "def h_double_cut(m, gamma: list, N, F=122, F2=4100):\n",
    "    g1, g2 = gamma\n",
    "    i = np.arange(1, F2+1, step=1)\n",
    "    alpha_i = [_i**(-g1) if _i < F else _i**(-g2) for _i in i]\n",
    "    alpha = np.sum(alpha_i, axis=0)\n",
    "    return F2 - np.sum((1-np.power(i[:F], -g1)/alpha)**m, axis=0) - np.sum((1-np.power(i[F:], -g2)/alpha)**m, axis=0)\n",
    "\n",
    "def h_triple(m, gamma: list, N, F1=122, F2=4100):\n",
    "    g1, g2 = gamma\n",
    "    i = np.arange(1, N+1, step=1)\n",
    "    \n",
    "    b = 1./(F1**(g1-g2)*np.sum([_i**(-g1) for _i in i[:F1]])+np.sum([_i**(-g2) for _i in i[F1:F2]]) + (F2**(-g2))*np.exp(0.002*F2)*np.sum([np.exp(-0.002*_i) for _i in i[F2:]]))\n",
    "    c = b * (F2**(-g2))*np.exp(0.002*F2)\n",
    "    a = b * F1**(g1-g2)\n",
    "    return N - np.sum((1-a*np.power(i[:F1], -g1))**m, axis=0) - np.sum((1-b*np.power(i[F1:F2], -g2))**m, axis=0) - np.sum((1-c*np.exp(-0.002*i[F2:]))**m, axis=0)\n",
    "\n",
    "def h_rho(m,f: np.array,N):\n",
    "    return N - np.sum(np.exp(-f/f.sum()*m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(28,24))\n",
    "\n",
    "skip_bins=5\n",
    "ax.scatter(data[\"M\"], data[\"diffWords\"], color=\"gray\", s=200, label=\"data\")\n",
    "\n",
    "#ax.scatter(data[\"nullteo\"][\"M\"], data[\"nullteo\"][\"diffWords\"], color=\"orange\", s=250, label=\"sampling_i**-0.8\")\n",
    "ax.scatter(data[\"mazzolini\"][\"M\"], data[\"mazzolini\"][\"diffWords\"], color=\"darkorange\", s=250, label=\"sampling_ensamble\")\n",
    "\n",
    "\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(data[\"M\"], data[\"diffWords\"],statistic='mean', bins=np.logspace(np.log10(data[\"M\"].min()),np.log10(max(data[\"M\"])), 25))\n",
    "\n",
    "ax.plot((bin_edges[:-1][:-skip_bins] + bin_edges[1:][:-skip_bins])/2, bin_means[:-skip_bins], color='blue', lw=10, marker=\"o\", ms=25, label='binned average')\n",
    "\n",
    "\n",
    "x_bins=np.logspace(np.log10(data[\"M\"].min()),np.log10(max(data[\"M\"])))\n",
    "ax.plot(x_bins, [h(x, 0.86, len(f.dropna())) for x in x_bins], lw=15, alpha=0.6, ls=\"--\", c=\"orange\", label=\"conto mazzolini\")\n",
    "ax.plot(x_bins, [h_double(x, [0.5, 0.9], len(data[\"freq\"].dropna()),F=122) for x in x_bins], lw=15, alpha=0.6, ls=\"--\", c=\"darkred\", label=\"mazzolini double_scaling\")\n",
    "ax.plot(x_bins, [h_double_cut(x, [0.5, 0.9], len(data[\"freq\"].dropna()),F=122) for x in x_bins], lw=15, alpha=0.6, ls=\"--\", c=\"darkorange\", label=\"mazzolini double_scaling_cut\")\n",
    "ax.plot(x_bins, [h_triple(x, [0.5, 1.0], len(data[\"freq\"].dropna()), F1=122, F2=4100) for x in x_bins], lw=15, alpha=0.6, ls=\"--\", c=\"red\", label=\"mazzolini triple_scaling\")\n",
    "#ax.plot(x_bins, [h_rho(x, f.dropna(), len(f.dropna())) for x in x_bins], lw=15, alpha=0.6, ls=\"--\", c=\"purple\", label=\"$N-\\Sigma_i P_i(0|M_s)$\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Number of genes expressed\", fontsize=35)\n",
    "ax.set_xlabel(\"UMI per cell, $M_s$\", fontsize=35)\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "ax.legend(fontsize=25)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"heaps_{tissue}_mazzolini_teo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(1,3e4, 30000)\n",
    "f=1/X\n",
    "f=f/sum(f)\n",
    "plt.plot(X,f, lw=10)\n",
    "\n",
    "f=[x**-0.5 if x < 122 else x**(-1) for x in X]\n",
    "f=f/sum(f)\n",
    "plt.plot(X,f, lw=8, alpha = 0.4)\n",
    "\n",
    "f=[x**-0.5 if x < 122 else x**(-1) for x in X[:4100]]\n",
    "f=f/sum(f)\n",
    "plt.plot(X[:4100],f, lw=6, ls=\":\", alpha = 0.4)\n",
    "\n",
    "f=[x**-0.5 if x < 122 else x**(-1) if x < 4100 else np.exp(-0.002*x) for x in X]\n",
    "f=f/sum(f)\n",
    "plt.plot(X,f, lw=4, ls=\"--\", alpha = 0.4)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-10,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = \"Bone-Marrow_c-Kit\"\n",
    "#tissue = \"bonemarrow_M100\"\n",
    "\n",
    "data = load_tissue(tissue, \"data\")\n",
    "\n",
    "for method in [\"nullteo\",\"mazzolini\"]:\n",
    "    try:\n",
    "        data[method] = load_tissue(tissue, method)\n",
    "\n",
    "        means_null = data[method]['means']\n",
    "        var_null = data[method]['var']\n",
    "        f_null = data[method]['freq']\n",
    "        f_null[np.isnan(f_null)]=0\n",
    "        O_null = data[method]['O']\n",
    "        M_null = data[method][\"M\"]\n",
    "        cv2_null = data[method]['cv2']\n",
    "        diffWords_null = data[method]['diffWords']\n",
    "        means_nozero_null = data[method]['means_nonzero']\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "    \n",
    "\n",
    "means = data['means']\n",
    "var = data['var']\n",
    "f = data['freq']\n",
    "O = data['O']\n",
    "M = data[\"M\"]\n",
    "cv2 = data['cv2']\n",
    "diffWords = data['diffWords']\n",
    "means_nozero = data['means_nonzero']\n",
    "\n",
    "#mazzolini(M, f, tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontiers_analysis import null_model\n",
    "null_model(M.sample(500), f, tissue)\n",
    "os.system(f\"mv data_{tissue}_null.pkl mca/data_{tissue}_null.pkl\")\n",
    "\n",
    "\n",
    "null_model(M.sample(500), pd.Series(index=[\"g%d\"%g for g in range(len(f))], data = [(i+1)**-0.8 for i in range(len(f))]), tissue)\n",
    "os.system(f\"mv data_{tissue}_null.pkl mca/data_{tissue}_nullteo.pkl\")\n",
    "\n",
    "\n",
    "#mazzolini(M.sample(500),f,tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "x = np.arange(1, len(f))\n",
    "plt.ylabel(\"$Frequency, f_i$\", fontsize=24)\n",
    "plt.xlabel(\"$RANK, i$\", fontsize=24)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(1e-7,1)\n",
    "plt.plot(x, 1./x, 'g--', lw=2, label='$i^{-1}$')\n",
    "plt.plot(np.sort(f)[::-1], c='blue', lw=8, label='Genes')\n",
    "plt.plot(np.sort(f_null)[::-1], c='orange', ls='--', lw=6, label='null_model')\n",
    "plt.legend(fontsize=24)\n",
    "plt.show()\n",
    "fig.savefig(\"zipf_null_0.pdf\")\n",
    "fig.savefig(\"zipf_null_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.scatter(M, diffWords, label='samples')\n",
    "plt.scatter(M_null, diffWords_null, label='null_model')\n",
    "plt.xlabel(\"Realization size\", fontsize=22)\n",
    "plt.ylabel(\"#different words\", fontsize=22)\n",
    "#bin_means, bin_edges, binnumber = stats.binned_statistic(M, diffWords,statistic='mean', bins=np.linspace(0,max(M)))\n",
    "#plt.hlines(bin_means[:-15], bin_edges[:-1][:-15], bin_edges[1:][:-15], colors='r', lw=5, label='binned average')\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlim(0,max(M)*1.1)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "fig.savefig(\"heaps_null_o.pdf\")\n",
    "fig.savefig(\"heaps_null_o.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(figsize=(15,8))\n",
    "ax.scatter(means_null.reindex_like(means.drop_duplicates()), cv2_null.reindex_like(means.drop_duplicates()), c='orange', label='mazzolini')\n",
    "plotcv2mean(means.values, var.values, ax=ax, normalisation_str='counts')\n",
    "fig.savefig(\"cvmean_loglog.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 10\n",
    "rang = (0-0.5/bins, 1+0.5/bins)\n",
    "fig, ax =plt.subplots(1,2, figsize=(20,10))\n",
    "ax[0].hist(np.array(O.dropna(), dtype=float), histtype='step', lw=5, range = rang, color='blue', density=True, bins=bins, label='data')\n",
    "if \"O_null\" in vars().keys():\n",
    "    ax[0].hist(np.array(O_null, dtype=float), histtype='step', lw=5, range = rang, bins=bins, color='orange', ls='--', density=True, label='Mazzolini')\n",
    "    \n",
    "if \"O_null_1\" in vars().keys():\n",
    "    ax[0].hist(np.array(O_null_1, dtype=float), histtype='step', lw=5, range = rang, bins=bins, color='green', ls='--', density=True, label='null_1')\n",
    "ax[0].set_xlabel(\"$o_i$\", fontsize=24)\n",
    "ax[0].set_ylabel(\"pdf\", fontsize=24)\n",
    "ax[0].legend(fontsize=20)\n",
    "\n",
    "ax[1].hist(np.array(O.dropna(), dtype=float), histtype='step', lw=5, range = rang, color='blue', density=True, bins=bins, label='data')\n",
    "if \"O_null\" in vars().keys():\n",
    "    ax[1].hist(np.array(O_null, dtype=float), histtype='step', lw=5, range = rang, bins=bins, color='orange', ls='--', density=True, label='Mazzolini')\n",
    "    \n",
    "if \"O_null_1\" in vars().keys():\n",
    "    ax[1].hist(np.array(O_null_1, dtype=float), histtype='step', lw=5, range = rang, bins=bins, color='green', ls='--', density=True, label='null_1')\n",
    "ax[1].set_xlabel(\"$o_i$\", fontsize=24)\n",
    "ax[1].set_ylabel(\"pdf\", fontsize=24)\n",
    "ax[1].legend(fontsize=20)\n",
    "\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xscale('log')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"U_null_0.pdf\")\n",
    "fig.savefig(\"U_null_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
