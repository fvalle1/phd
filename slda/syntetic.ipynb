{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import dirichlet, multinomial, normal, negative_binomial\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 250 # documents\n",
    "W = 1000 # words\n",
    "Wk = 100 # keywords\n",
    "K = 10 #topics\n",
    "alpha = 1./K\n",
    "beta = 1./K\n",
    "eta = 100/K\n",
    "sigma2 = 0.01\n",
    "\n",
    "Nd = [100 for doc in range(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = dirichlet(np.repeat(alpha, W), size=K)\n",
    "assert(phi.shape==(K,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(phi[0])\n",
    "\n",
    "ax.set_xlabel(\"W\", fontsize=25)\n",
    "ax.set_ylabel(\"$\\\\phi_K$\", fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = dirichlet(np.repeat(beta, K), size=D)\n",
    "assert(theta.shape==(D,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(theta[0])\n",
    "\n",
    "ax.set_xlabel(\"K\", fontsize=25)\n",
    "ax.set_ylabel(\"$\\\\theta_d$\", fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([[np.argmax(multinomial(1, theta[i])) for j in range(Nd[i])]\n",
    "     for i in range(D)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_bar = np.average(z, 1)\n",
    "Y = [normal(eta*z_bar_d, sigma2) for z_bar_d in z_bar]\n",
    "assert(len(Y)==D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[np.argmax(multinomial(1,phi[z[i,j]])) for j in range(Nd[i])]\n",
    "     for i in range(D)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for doc in range(D):\n",
    "    doc_dict, doc_ab = np.unique(W[doc], return_counts=True)\n",
    "    df = df.join(pd.Series(index=doc_dict, data=doc_ab, name=\"doc_{}\".format(doc)), how=\"outer\")\n",
    "    \n",
    "\n",
    "df = df.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma = np.array([negative_binomial(y/(y-1), 1./y, size=Wk) for y in Y])\n",
    "gamma = np.array([y for y in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.DataFrame()\n",
    "\n",
    "\n",
    "for doc in range(D):\n",
    "    doc_dict, doc_ab = np.unique(gamma[doc], return_counts=True)\n",
    "    df_meta = df_meta.join(pd.Series(index=doc_dict, data=doc_ab, name=\"doc_{}\".format(doc)), how=\"outer\")\n",
    "    \n",
    "\n",
    "df_meta = df_meta.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "freq = df.sum(1).sort_values(ascending=False).values\n",
    "\n",
    "ax.plot(freq/freq.sum())\n",
    "ax.plot([1,len(freq)], [.1, .1/len(freq)])\n",
    "\n",
    "ax.set_xlabel(\"rank\", fontsize=25)\n",
    "ax.set_ylabel(\"$f_i$\", fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "plt.scatter(Y,np.argmax(theta, axis=1))\n",
    "\n",
    "ax.set_xlabel(\"$Y_d$\", fontsize=25)\n",
    "ax.set_ylabel(\"$\\\\theta_d$\", fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-native",
   "metadata": {},
   "source": [
    "# Models\n",
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = lda.fit_transform(df.transpose().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist([np.sum(kl_div(topic_dist[i], theta[i])) for i in range(D)], density=True)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"KL_divergence\", fontsize=25)\n",
    "ax.set_ylabel(\"pdf\", fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-dallas",
   "metadata": {},
   "source": [
    "## sLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train-data.txt\", \"w\") as file:\n",
    "    for doc in df.columns:\n",
    "        total = (df[doc]>0).sum()\n",
    "        file.write(str(total))\n",
    "        for iw,(w,c) in enumerate(df[doc].items()):\n",
    "            if c>0:\n",
    "                file.write(f\" {iw}:{c}\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train-labels.txt\", \"w\") as file:\n",
    "    for y in Y:\n",
    "        file.write(str(int(round(y,0)))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-stroke",
   "metadata": {},
   "source": [
    "### Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "slda_topic_dist = pd.read_csv(\"sldasyntetic/final.gamma\", sep=\" \", header=None)\n",
    "slda_topic_dist.columns = [\"Topic %d\"%(t+1) for t in range(slda_topic_dist.shape[1])]\n",
    "slda_topic_dist = slda_topic_dist.divide(slda_topic_dist.sum(1),0)\n",
    "slda_topic_dist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "slda_word_dist = pd.DataFrame(index=df.index, columns = [\"Topic %d\"%(t+1) for t in range(10)]).fillna(0)\n",
    "slda_word_dist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_word(line, sample):\n",
    "    new_sample = pd.Series(name=sample, index=df_word_dist.index, dtype=object)\n",
    "    for token in line:\n",
    "        idx, cnt = token.split(\":\")\n",
    "        new_sample.at[new_sample.index[int(idx)]]=int(cnt)\n",
    "    return new_sample\n",
    "    \n",
    "def assign_doc(sample):\n",
    "    global df_word_dist_temp\n",
    "    df_word_dist_temp = df_word_dist_temp.join(sample, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(6)\n",
    "df_word_dist_temp = pd.DataFrame()\n",
    "with open(\"sldasyntetic/word-assignments.dat\") as file:\n",
    "    lines = file.read().split(\"\\n\")      \n",
    "    w = [pool.apply_async(assign_word, args=([line.split(\" \")[1:], sample]), callback = assign_doc, error_callback=lambda err:log.error(err)) for line, sample in zip(lines, df_word_dist.columns)]\n",
    "    \n",
    "    pool.close()\n",
    "\n",
    "pool.join()\n",
    "df_word_dist_temp=df_word_dist_temp.reindex(index=df_word_dist.index, columns=df_word_dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, data in df_word_dist_temp.apply(lambda x: np.unique(x[~x.isna()],return_counts=True), 1).items():\n",
    "    for t, c in zip(*data):\n",
    "        slda_word_dist.at[g,slda_word_dist.columns[t]]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "slda_word_dist = slda_word_dist.divide(slda_word_dist.sum(0),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-banking",
   "metadata": {},
   "source": [
    "## hSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/phd/hSBM_Topicmodel/\")\n",
    "from sbmtm import sbmtm\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, sbmtm\n",
    "importlib.reload(sbmtm)\n",
    "from sbmtm import sbmtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm = sbmtm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm.make_graph_from_BoW_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm.fit(n_init=3, B_min=8, B_max=15, parallel=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.draw_hierarchy(hsbm.state,\n",
    "                 layout=\"bipartite\",\n",
    "                 hedge_pen_width=8, \n",
    "                 hvertex_size=25, \n",
    "                 vertex_kind=hsbm.g.vertex_properties[\"kind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle as pickle\n",
    "\n",
    "os.system(\"mkdir -p syntetic\")\n",
    "os.chdir(\"syntetic\")\n",
    "hsbm.save_data()\n",
    "hsbm.save_graph()\n",
    "os.chdir(\"..\")\n",
    "\n",
    "with open(\"sbmtm.pkl\", \"wb\") as file:\n",
    "    pickle.dump(hsbm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-festival",
   "metadata": {},
   "source": [
    "## triSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/phd/trisbm/\")\n",
    "from trisbm import trisbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trisbm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.index = [\"#{}\".format(w) for w in df_meta.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_graph(df.append(df_meta), lambda w: 2 if \"#\" in str(w) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(n_init=3, B_min=12, B_max=20, parallel=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.draw_hierarchy(model.state,\n",
    "                 hedge_pen_width=8, \n",
    "                 hvertex_size=25, \n",
    "                 vertex_kind=model.g.vertex_properties[\"kind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle as pickle\n",
    "\n",
    "os.system(\"mkdir -p syntetic_key\")\n",
    "os.chdir(\"syntetic_key\")\n",
    "model.save_data()\n",
    "model.save_graph()\n",
    "os.chdir(\"..\")\n",
    "\n",
    "with open(\"trisbm.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-philippines",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-wealth",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_traces([\n",
    "    go.Bar(x=[0], y=[hsbm.get_mdl()], name=\"hsbm\"),\n",
    "    go.Bar(x=[1], y=[model.get_mdl()], name=\"trisbm\")\n",
    "])\n",
    "    \n",
    "fig.update_layout(\n",
    "{\n",
    "    \"xaxis\":{\n",
    "        \"tickfont\":{\n",
    "            \"size\":25\n",
    "        },\n",
    "        \"tickmode\": \"array\",\n",
    "        \"tickvals\": [0,1],\n",
    "        \"ticktext\": [\"hsbm\", \"trisbm\"],\n",
    "    },\n",
    "     \"yaxis\":{\n",
    "        \"title\":\"Description lenght\",\n",
    "        \"titlefont_size\":25,\n",
    "         \"tickfont\":{\n",
    "            \"size\":25\n",
    "        }\n",
    "    }\n",
    "}\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(\"Sigma_topics.pdf\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-diversity",
   "metadata": {},
   "source": [
    "### Topic dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_dist = pd.read_csv(\"syntetic/topsbm_level_0_topic-dist.csv\", index_col=1).drop(\"i_doc\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "trisbm_dist = pd.read_csv(\"syntetic_key/trisbm_level_0_topic-dist.csv\", index_col=1).drop(\"i_doc\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(a,b, epsilon = 0):\n",
    "    la = len(a)\n",
    "    lb = len(b)\n",
    "    if la>lb:\n",
    "        return a+epsilon,np.concatenate((b,np.zeros(la-lb)))+epsilon\n",
    "    elif la<lb:\n",
    "        return np.concatenate((a,np.zeors(lb-la)))+epsilon,b+epsilon\n",
    "    return a+epsilon,b+epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_hsbm_kl = [np.sum(kl_div(*padding(theta[idoc], hsbm_dist.values[idoc], 1e-10))) for idoc in range(D)]\n",
    "\n",
    "real_tri_kl = [np.sum(kl_div(*padding(theta[idoc], trisbm_dist.values[idoc], 1e-10))) for idoc in range(D)]\n",
    "\n",
    "real_lda_kl = [np.sum(kl_div(*padding(theta[idoc], topic_dist[idoc], 1e-10))) for idoc in range(D)]\n",
    "\n",
    "real_slda_kl = [np.sum(kl_div(*padding(theta[idoc], slda_topic_dist.values[idoc], 1e-10))) for idoc in range(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "def get_scatter(data, name):\n",
    "    hist = np.histogram(data, density=True)\n",
    "\n",
    "    return go.Scatter(x=(hist[1][1:]+hist[1][:-1])/2, \n",
    "                      y=hist[0], \n",
    "                      mode=\"lines\", \n",
    "                      line={\"shape\":\"hvh\", \"width\":8}, \n",
    "                      name=name)\n",
    "    \n",
    "fig.add_traces([\n",
    "    get_scatter(data, name)\n",
    "    \n",
    "    for data, name in zip([real_hsbm_kl, real_tri_kl, real_lda_kl, real_slda_kl],\n",
    "                         [\"hsbm\", \"trisbm\", \"lda\", \"slda\"])\n",
    "])\n",
    "    \n",
    "fig.update_layout(\n",
    "{\n",
    "    \"xaxis\":{\n",
    "        \"title\":\"KL (P(topic|sample),P(planted latent variable|sample))\",\n",
    "        \"titlefont_size\":25\n",
    "    },\n",
    "     \"yaxis\":{\n",
    "        \"title\":\"documents\",\n",
    "        \"titlefont_size\":25\n",
    "    },\n",
    "    \"barmode\":'overlay'\n",
    "}\n",
    ")\n",
    "fig.update_traces(opacity=0.5)\n",
    "fig.show()\n",
    "fig.write_image(\"KL_topics.pdf\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-issue",
   "metadata": {},
   "source": [
    "### Word-dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsbm_word_dist = pd.read_csv(\"syntetic/topsbm_level_0_word-dist.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "trisbm_word_dist = pd.read_csv(\"syntetic_key/trisbm_level_0_word-dist.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_word_dist = lda.components_.T\n",
    "lda_word_dist = lda_word_dist/np.sum(lda_word_dist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_hsbm_kl_words = [[np.sum(kl_div(*padding(phi[ilatent], hsbm_word_dist.values.T[itopic], 1e-10))) for ilatent in range(K)]\n",
    " for itopic in range(hsbm_word_dist.shape[1])]\n",
    "\n",
    "real_tri_kl_words = [[np.sum(kl_div(*padding(phi[ilatent], trisbm_word_dist.values.T[itopic], 1e-10))) for ilatent in range(K)]\n",
    " for itopic in range(trisbm_word_dist.shape[1])]\n",
    "\n",
    "real_lda_kl_words = [[np.sum(kl_div(*padding(phi[ilatent], lda_word_dist.T[itopic], 1e-10))) for ilatent in range(K)]\n",
    " for itopic in range(lda_word_dist.shape[1])]\n",
    "\n",
    "real_slda_kl_words = [[np.sum(kl_div(*padding(phi[ilatent], slda_word_dist.values.T[itopic], 1e-10))) for ilatent in range(K)]\n",
    " for itopic in range(df_word_dist.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.sort(real_lda_kl_words, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.sort(real_tri_kl_words, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_traces([\n",
    "    go.Histogram(x=np.ravel(real_hsbm_kl_words), name=\"hsbm\"),\n",
    "    go.Histogram(x=np.ravel(real_tri_kl_words), name=\"trisbm\"),\n",
    "    go.Histogram(x=np.ravel(real_lda_kl_words), name=\"lda\"),\n",
    "    go.Histogram(x=np.ravel(real_slda_kl_words), name=\"slda\")\n",
    "])\n",
    "    \n",
    "fig.update_layout(\n",
    "{\n",
    "    \"xaxis\":{\n",
    "        \"title\":\"KL (P(word|topic),P(word|planted variable))\",\n",
    "        \"titlefont_size\":25\n",
    "    },\n",
    "     \"yaxis\":{\n",
    "        \"title\":\"pait topic-latent variable\",\n",
    "        \"titlefont_size\":25\n",
    "    },\n",
    "    \"barmode\":'overlay'\n",
    "}\n",
    ")\n",
    "fig.update_traces(opacity=0.3)\n",
    "fig.show()\n",
    "fig.write_image(\"KL_words.pdf\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-bride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
