{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "log = logging.getLogger(\"slda\")\n",
    "hdl = logging.StreamHandler()\n",
    "hdl.setLevel(logging.DEBUG)\n",
    "hdl.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "log.addHandler(hdl)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-cartoon",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allfiles = pd.read_csv(\"../miRNA/files.dat\", index_col=0)\n",
    "df_allfiles[\"level_0\"][:2], df_allfiles[\"index\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-honor",
   "metadata": {},
   "source": [
    "# Process miRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mirna = pd.read_csv(\"../miRNA/mainTable_miRNA.csv\", index_col=0).reindex(columns=df_allfiles[\"level_0\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mirna.transpose().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_jobs=12)\n",
    "topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train-label.txt\", topics.argmax(1).T, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-texas",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv(\"../miRNA/mainTable_fpkm.csv\", index_col=0).reindex(columns=df_allfiles[\"index\"])\n",
    "df_files= pd.read_csv(\"../miRNA/files_fpkm.dat\", index_col=0).reindex(index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(X = df.transpose(), obs=df_files)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(index=adata.var[adata.var[\"highly_variable\"]].index).applymap(lambda fpkm: np.log2(fpkm+1))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train-data.txt\",\"w\") as file:\n",
    "    for sample in df.columns:\n",
    "        doc = df[sample].round().astype(int)\n",
    "        file.write(f\"{len(doc[doc>0])} \")\n",
    "        for el in [f\"{iw}:{w[1]}\" for iw,w in enumerate(doc.items()) if w[1] > 0]:\n",
    "            file.write(el+\" \")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-cyprus",
   "metadata": {},
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_csv(\"mirna/final.gamma\", sep=\" \", header=None)\n",
    "df_topics.index = df_allfiles.index\n",
    "df_topics.columns = [\"Topic %d\"%(t+1) for t in range(df_topics.shape[1])]\n",
    "df_topics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_dist = pd.DataFrame(index=df.index, columns = [\"Topic %d\"%(t+1) for t in range(10)]).fillna(0)\n",
    "df_word_dist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_word(line, sample):\n",
    "    new_sample = pd.Series(name=sample, index=df_word_dist.index, dtype=object)\n",
    "    for token in line:\n",
    "        idx, cnt = token.split(\":\")\n",
    "        new_sample.at[new_sample.index[int(idx)]]=int(cnt)\n",
    "    return new_sample\n",
    "    \n",
    "def assign_doc(sample):\n",
    "    global df_word_dist_temp\n",
    "    df_word_dist_temp = df_word_dist_temp.join(sample, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(6)\n",
    "df_word_dist_temp = pd.DataFrame()\n",
    "with open(\"mirna/word-assignments.dat\") as file:\n",
    "    lines = file.read().split(\"\\n\")\n",
    "    log.debug(len(lines))\n",
    "    log.debug(lines[0][:50])        \n",
    "    w = [pool.apply_async(assign_word, args=([line.split(\" \")[1:], sample]), callback = assign_doc, error_callback=lambda err:log.error(err)) for line, sample in zip(lines, df_word_dist.columns)]\n",
    "    \n",
    "    pool.close()\n",
    "\n",
    "pool.join()\n",
    "df_word_dist_temp=df_word_dist_temp.reindex(index=df_word_dist.index, columns=df_word_dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, data in df_word_dist_temp.apply(lambda x: np.unique(x[~x.isna()],return_counts=True), 1).items():\n",
    "    for t, c in zip(*data):\n",
    "        df_word_dist.at[g,df_word_dist.columns[t]]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_dist = df_word_dist.divide(df_word_dist.sum(0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Topic 4\"\n",
    "for g in df_word_dist[topic][df_word_dist[topic]>df_word_dist[topic].quantile(0.95)].index:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keyword_dist = pd.DataFrame(data=lda.components_.T, index=df_mirna.index, columns = [\"Metadatum %d\"%(m+1) for m in range(topics.shape[1])])\n",
    "df_keyword_dist=df_keyword_dist.divide(df_keyword_dist.sum(0),1)\n",
    "df_keyword_dist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.DataFrame(data=topics, index=df_allfiles.index, columns = [\"Metadatum %d\"%(m+1) for m in range(topics.shape[1])])\n",
    "df_metadata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-suspect",
   "metadata": {},
   "source": [
    "## Distinctivness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from distinctivness_helper import get_distinctivness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_distinctivness(tf.convert_to_tensor(df_keyword_dist.transpose().values)).numpy()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D = pd.DataFrame(data=out, index=df_keyword_dist.index, columns=df_keyword_dist.columns)\n",
    "df_D.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in df_D[\"Metadatum 10\"].sort_values(ascending=False).index[:30]:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-involvement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
