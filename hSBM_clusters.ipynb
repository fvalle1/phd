{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from TCGA_files import get_tcga_tissue\n",
    "#from ensembleAPI import geneinfo, genesinfo\n",
    "from sklearn import metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hsbmpy import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 1\n",
    "algorithm = 'trisbm'\n",
    "directory = \"trisbm/wikipedia_key\"\n",
    "L=get_max_available_L(directory, algorithm)\n",
    "df_clusters = pd.read_csv(\"%s/%s/%s_level_%d_clusters.csv\"%(directory,algorithm,algorithm,L), header=[0])\n",
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_files = pd.read_csv(\"https://storage.googleapis.com/gtex_analysis_v8/annotations/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt\", sep='\\t')\n",
    "#df_files.set_index('SAMPID', inplace=True)\n",
    "#df_files.dropna(how='all', axis=0).to_csv(\"%s/files.dat\"%directory, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_csv(\"%s/files.dat\"%directory, index_col=[0], header=[0]).dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "samples = pd.read_csv(\"%s/%s/%s_level_0_clusters.csv\"%(directory,algorithm,algorithm), header=[0]).astype(str).values.ravel()\n",
    "samples=samples[samples!=\"nan\"]\n",
    "df_files = df_files.reindex(index=samples).dropna(how=\"all\", axis=0).fillna(\"unknown\")\n",
    "labels = df_files.columns\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Subtype_Selected']\n",
    "#labels = ['cancer.type', \"Subtype_Selected\"]\n",
    "#labels=['SMTS', \"SMTSD\"]\n",
    "#labels=[\"Type\", \"Subtype\"]\n",
    "#labels = [\"primary_site\", \"tissue_hd\"]\n",
    "df_files[labels[0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for normalise in [True, False]:\n",
    "    for label in labels:\n",
    "        for level in np.arange(L+1)[::-1]:\n",
    "            if level==0:\n",
    "                pass\n",
    "                #continue\n",
    "            print(normalise, label, level)\n",
    "            cluster = get_cluster_given_l(level, directory,algorithm=algorithm)\n",
    "            fraction_sites = get_fraction_sites(cluster,df_files=df_files,label=label, normalise=normalise)\n",
    "\n",
    "            clustersinfo = get_clustersinfo(cluster,fraction_sites)\n",
    "            plot_cluster_composition(fraction_sites,directory,level,label=label, normalise=normalise,algorithm=algorithm)\n",
    "            make_heatmap(fraction_sites, directory, label, level, normalise=normalise,algorithm=algorithm)\n",
    "\n",
    "            clustersinfo = get_clustersinfo(cluster,fraction_sites)            \n",
    "            if not normalise:\n",
    "                plot_maximum(clustersinfo,cluster,label,level, directory,algorithm=algorithm)\n",
    "                plot_maximum_size(clustersinfo,label,level, directory,algorithm=algorithm)\n",
    "                plot_maximum_label(clustersinfo,label,level, directory,algorithm=algorithm)\n",
    "                plot_sizes(level,directory, algorithm=algorithm)\n",
    "            try:\n",
    "                cluster = get_cluster_given_l(level, directory,algorithm=algorithm)\n",
    "                fraction_sites = get_fraction_sites(cluster,df_files=df_files,label=label, normalise=normalise)\n",
    "\n",
    "                clustersinfo = get_clustersinfo(cluster,fraction_sites)\n",
    "                plot_cluster_composition(fraction_sites,directory,level,label=label, normalise=normalise,algorithm=algorithm)\n",
    "                make_heatmap(fraction_sites, directory, label, level, normalise=normalise,algorithm=algorithm)\n",
    "\n",
    "                clustersinfo = get_clustersinfo(cluster,fraction_sites)            \n",
    "                if not normalise:\n",
    "                    plot_maximum(clustersinfo,cluster,label,level, directory,algorithm=algorithm)\n",
    "                    plot_maximum_size(clustersinfo,label,level, directory,algorithm=algorithm)\n",
    "                    plot_maximum_label(clustersinfo,label,level, directory,algorithm=algorithm)\n",
    "                    plot_sizes(level,directory, algorithm=algorithm)\n",
    "            except:\n",
    "                print(*sys.exc_info())\n",
    "            continue\n",
    "            shuffle_files(df_files,label).to_csv(\"%s/files_shuffles.dat\"%directory, index=True)\n",
    "            fraction_sites_shuffle = get_fraction_sites(cluster, df_files=pd.read_csv(\"%s/files_shuffles.dat\"%directory, index_col=[0]),label=label, normalise=normalise)\n",
    "            clustersinfo_shuffle = get_clustersinfo(cluster, fraction_sites_shuffle)\n",
    "            plot_cluster_composition(fraction_sites_shuffle,directory,level, label=label, shuffled=True, normalise=normalise, algorithm=algorithm)\n",
    "            if not normalise:\n",
    "                plot_maximum(clustersinfo,cluster,label,level,directory,clustersinfo_shuffle,algorithm=algorithm)\n",
    "                plot_maximum_size(clustersinfo,label,level, directory,clustersinfo_shuffle,algorithm=algorithm)\n",
    "                plot_maximum_label(clustersinfo,label,level, directory,clustersinfo_shuffle,algorithm=algorithm)\n",
    "                plot_labels_size(clustersinfo,label,level, directory,clustersinfo_shuffle,algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##useful for R clustree plot\n",
    "def reindex(x):\n",
    "    i=0\n",
    "    last=x[0]\n",
    "    new = []\n",
    "    for xi in x:\n",
    "        if xi == last:\n",
    "            pass\n",
    "        else:\n",
    "            i+=1\n",
    "            last=xi\n",
    "        new.append(i)\n",
    "    return new\n",
    "\n",
    "df_labels = pd.DataFrame()\n",
    "shape = df_clusters.dropna().shape\n",
    "files = pd.read_csv(\"%s/%s/%s_level_4_clusters.csv\"%(directory,algorithm,algorithm), header=[0]).astype(str).values.ravel()\n",
    "files = files[files!=\"nan\"]\n",
    "\n",
    "for level in np.arange(L+1)[::-1]:\n",
    "    df_clusters = pd.read_csv(\"%s/%s/%s_level_%d_clusters.csv\"%(directory,algorithm,algorithm,level), header=[0])\n",
    "    print(\"level \", level, \"with \", df_clusters.shape[1], \" clusters\")\n",
    "    currentlevellabels = []\n",
    "    for file in files:\n",
    "        s = df_clusters[df_clusters.isin([file])].any(0)\n",
    "        a = s.index[s]\n",
    "        currentlevellabels.append(int(a[0][8:])-1)\n",
    "    df_labels.insert(0,'l%d'%level,currentlevellabels)\n",
    "    del currentlevellabels\n",
    "filelabels = []\n",
    "filesublabels = []\n",
    "for file in files:\n",
    "    try:\n",
    "        filelabels.append(get_file(file, df_files)[labels[0]])\n",
    "        filesublabels.append(get_file(file, df_files)[labels[1]])\n",
    "    except:\n",
    "        filelabels.append('unknown')\n",
    "        filesublabels.append('unknown')\n",
    "        print(*sys.exc_info())\n",
    "df_labels.insert(0,'tissue', filelabels)\n",
    "df_labels.insert(0,'subtissue', filesublabels)\n",
    "df_labels.sort_values(by=['tissue','subtissue'], inplace=True)\n",
    "df_labels.sort_values(by=[\"l%d\"%l for l in np.arange(L+1)[::-1]], axis=0, inplace=True)\n",
    "filelabels = df_labels['tissue']\n",
    "filesublabels = df_labels['subtissue']\n",
    "df_labels = df_labels.apply(reindex, axis=0)\n",
    "df_labels['tissue']=filelabels\n",
    "df_labels['subtissue']=filesublabels\n",
    "df_labels.to_csv(\"%s/%s/topsbm_labels.csv\"%(directory,algorithm), index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"clustersizes.txt\" in os.listdir(directory):\n",
    "    with open(\"%s/clustersizes.txt\"%directory, 'r') as f:\n",
    "        xl=np.array(f.read().split()).astype(int)\n",
    "else:\n",
    "    try:\n",
    "        xl = getclustersizesarray(directory, L)\n",
    "        with open(\"%s/clustersizes.txt\" % directory, 'w') as f:\n",
    "            for x in xl:\n",
    "                f.write(\"%d\\n\" % x)\n",
    "    except:\n",
    "        print(*sys.exc_info())\n",
    "        print(\"cannot save clustersizes.txt\")\n",
    "\n",
    "if \"topicsizes.txt\" in os.listdir(directory):\n",
    "    with open(\"%s/topicsizes.txt\"%directory) as f:\n",
    "        tl=np.array(f.read().split()).astype(int)\n",
    "else:\n",
    "    try:\n",
    "        tl = gettopicsizesarray(directory, L)\n",
    "        with open(\"%s/topicsizes.txt\" % directory, 'w') as f:\n",
    "            for x in tl:\n",
    "                f.write(\"%d\\n\" % x)\n",
    "    except:\n",
    "        print(\"cannot save topicsizes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_scores(directory, labels, algorithm=\"trisbm\", verbose=False)\n",
    "scores['trisbm'] = scores[labels[0]]\n",
    "scores[\"hsbm\"]=get_scores(\"trisbm/wikipedia\", labels, algorithm=\"topsbm\", verbose=False)[labels[0]]\n",
    "scores['shuffle'] = get_scores_shuffled(directory, df_files, label=labels[0], algorithm='trisbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18,15))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores,labels=[\"hsbm\",\"trisbm\", \"shuffle\"], V=\"norm_V\", alpha=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(1,5)\n",
    "ax.set_xlim(0,10)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_hierstructure.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18,15))\n",
    "ax = fig.subplots(1)\n",
    "#add_score_lines(ax,scores,[labels[0]],xl, h=True, c=True, alpha=1)\n",
    "h = np.array(scores['hsbm']['h'])\n",
    "c = np.array(scores['hsbm']['c'])\n",
    "ax.plot(scores['hsbm']['xl'],h, marker='o', ls='--', lw=10, ms=40, label='homogeneity')\n",
    "ax.plot(scores['hsbm']['xl'],c, marker='o', ls='-.', lw=10,ms=40, label='completeness')\n",
    "ax.plot(scores['hsbm']['xl'],scores['hsbm']['V'], marker='o', ms=40, ls='-', lw=10, label='score')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(0,1)\n",
    "#ax.plot(xl, 2*h*c/(h+c), ls='-',c='g')\n",
    "plt.xticks(fontsize=35)\n",
    "plt.yticks(fontsize=35)\n",
    "plt.legend(fontsize=35)\n",
    "\n",
    "ax.tick_params(labelsize=35, width=8, length=20)\n",
    "ax.tick_params(which=\"minor\", labelsize=35, width=5, length=15)\n",
    "\n",
    "plt.xlabel('number of clusters', fontsize=35)\n",
    "plt.ylabel('measure', fontsize=35)\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_primarysite.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['shuffle'] = get_scores_shuffled(directory, df_files, label=label, algorithm='topsbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[0]\n",
    "scores = {}\n",
    "for key,alg in zip([\"hsbm\",\"hierarchical\",\"lda\",\"kmeans\",\"tm\",\"wgcna\", \"nmf\"],[\"topsbm\",\"hierarchical-log\",\"lda\",\"kmeans\",\"tm\",\"wgcna\", \"nmf\"]):\n",
    "    print(key,alg)\n",
    "    try:\n",
    "        scores[key]= get_scores(directory, labels, df_files=df_files, algorithm=alg, verbose=False)[label]\n",
    "    except:\n",
    "        print(\"cannot find \", alg)\n",
    "        print(*sys.exc_info())\n",
    "scores['shuffle'] = get_scores_shuffled(directory, df_files, label=label, algorithm='topsbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label=\"SMTS\"\n",
    "#scores={}\n",
    "scores['hierarchical-tpm'] = get_scores(directory, labels, algorithm='hierarchical-tpm', verbose=False)[label]\n",
    "scores['lda-tpm'] = get_scores(directory, labels, algorithm='lda-tpm', verbose=False)[label]\n",
    "scores['hsbm-log2'] = get_scores(directory, labels, algorithm='topsbm-log', verbose=False)[label]\n",
    "scores['hsbm-log10'] = get_scores(directory, labels, algorithm='topsbm-log10', verbose=False)[label]\n",
    "scores['wgcna-tpm'] = get_scores(directory, labels, algorithm='wgcna-tpm', verbose=False)[label]\n",
    "scores['hsbm'] = get_scores(directory, labels, algorithm='topsbm', df_files=df_files, verbose=False)[label]\n",
    "scores['shuffle'] = get_scores_shuffled(directory, df_files, label=label, algorithm='topsbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"tissues\"] = get_scores(directory, labels, algorithm='topsbm', verbose=False)[labels[0]]\n",
    "scores[\"sub_tissues\"] = get_scores(directory, labels, algorithm='topsbm', verbose=False)[labels[1]]\n",
    "scores[labels[0]] = scores[\"tissues\"]\n",
    "scores[labels[1]] = scores[\"sub_tissues\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsbmpy import normalise_score\n",
    "if \"mixed\" in scores.keys():\n",
    "    scores.pop(\"mixed\")\n",
    "normalise_score(scores, base_algorithm=\"shuffle\", operation=lambda x,y: x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = {\n",
    "    \"all\": ['hsbm', 'tm', 'hierarchical', 'lda', 'wgcna', 'nmf','shuffle'],\n",
    "    \"subtypes\": [\"Subtype_Selected\", \"BRCA_Subtype_PAM50\",'shuffle'],\n",
    "    \"hsbm\": [\"hsbm\", \"hsbm-sweep\", \"hsbm-log2\",\"hsbm-log10\",'shuffle'],\n",
    "    \"subtissues\": [\"tissues\", \"sub_tissues\",'shuffle'],\n",
    "    \"hvhde\": [\"hsbm-hde\", \"hsbm-hv\", \"shuffle\"],\n",
    "    \"wgcna\": [\"wgcna\",\"wgcna-high\",\"wgcna-low\", \"shuffle\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,score in scores.items():\n",
    "    if score[\"xl\"][0]<score[\"xl\"][-1]:\n",
    "        score[\"xl\"].append(1000)\n",
    "        score[\"V\"].append(0)\n",
    "        score[\"norm_V\"]=list(score[\"norm_V\"])\n",
    "        score[\"norm_V\"].append(1)\n",
    "    else:\n",
    "        score[\"xl\"].insert(0,1000)\n",
    "        score[\"V\"].insert(0,0)\n",
    "        score[\"norm_V\"]=list(score[\"norm_V\"])\n",
    "        score[\"norm_V\"].insert(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores['hsbm-hv'] = get_scores(\"cancers/breast/hv\", labels, algorithm='topsbm', df_files=df_files, verbose=False)[labels[0]]\n",
    "scores['hsbm-hde'] = get_scores(\"cancers/breast\", labels, algorithm='topsbm', df_files=df_files, verbose=False)[labels[0]]\n",
    "scores['shuffle'] = get_scores_shuffled(directory, df_files, label=labels[0], algorithm='topsbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"cancers/lung/tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={}\n",
    "scores['wgcna'] = get_scores(\"cancers/lung/\", labels, algorithm='wgcna', verbose=False)[labels[0]]\n",
    "scores['wgcna-low'] = get_scores(\"cancers/lung/tests/low_filters\", labels, algorithm='wgcna', df_files=df_files, verbose=False)[labels[0]]\n",
    "scores['wgcna-high'] = get_scores(\"cancers/lung/tests/high_filters\", labels, algorithm='wgcna', df_files=df_files, verbose=False)[labels[0]]\n",
    "scores['shuffle'] = get_scores_shuffled(\"cancers/lung/\", df_files, label=labels[0], algorithm='wgcna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = \"all\"\n",
    "\n",
    "fig=plt.figure(figsize=(20,15))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores, V=\"norm_V\", labels=analyses[analysis])\n",
    "#ax.set_xscale('linear')\n",
    "plt.xlim(1,1100)\n",
    "plt.ylim(0,35)\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_%s.pdf\"%(directory,analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_data = {}\n",
    "bar_data[\"tpm\"] = {}\n",
    "bar_data[\"log\"] = {}\n",
    "\n",
    "for alg in [\"hsbm\", \"lda-tpm\", \"hierarchical-tpm\", \"wgcna-tpm\"]:\n",
    "    bar_data[\"tpm\"][alg] = max(scores[alg][\"V\"])\n",
    "for alg in [\"hsbm-log2\", \"lda\", \"hierarchical\", \"wgcna\"]:\n",
    "    bar_data[\"log\"][alg] = max(scores[alg][\"V\"])\n",
    "    \n",
    "n_algs = 4\n",
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "ax.bar([x*2.4 for x in range(n_algs)], list(zip(*bar_data[\"tpm\"].items()))[1],color=\"gray\", label=\"TPM\")\n",
    "ax.bar([0.8+x*2.4 for x in range(n_algs)], list(zip(*bar_data[\"log\"].items()))[1], color=\"red\", label=\"Log(TPM+1)\")\n",
    "ax.set_xticklabels(labels=[\"hsbm\",\"lda\", \"hierarchical\",\"wgcna\"], fontsize=35)\n",
    "ax.set_xticks([0.4+x*2.4 for x in range(n_algs)])\n",
    "ax.tick_params(labelsize=35)\n",
    "ax.set_ylim(0.4,1)\n",
    "ax.legend(fontsize=35)\n",
    "ax.set_ylabel(\"NMI score\", fontsize=35)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"{directory}/metric_scores_bars_log.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "labels = {}\n",
    "algs = [\"topsbm\", \"tm\", \"lda\", \"wgcna\", \"hierarchical-log\"]\n",
    "for algorithm, l in zip(algs,[1,0, 1, 1, 1]):\n",
    "    clusters[algorithm]=pd.read_csv(\"%s/%s/%s_level_%d_clusters.csv\"%(directory,algorithm,algorithm,l), header=[0])\n",
    "    print(algorithm, clusters[algorithm].shape[1])\n",
    "    labels[algorithm] = []\n",
    "    for sample in samples:\n",
    "        labels[algorithm].append(clusters[algorithm].columns[(clusters[algorithm]==sample).any()].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "for alg1, alg2 in zip([\"topsbm\", \"topsbm\", \"topsbm\", \"topsbm\", \"tm\", \"tm\", \"tm\", \"lda\", \"lda\", \"wgcna\"],[\"tm\",\"lda\", \"wgcna\", \"hierarchical-log\", \"lda\", \"wgcna\", \"hierarchical-log\", \"wgcna\", \"hierarchical-log\", \"hierarchical-log\"]):\n",
    "    print(alg1, \" & \", alg2.replace(\"-log\",\"\"), \" & \", \"{:.3f}\".format(float(v_measure_score(labels[alg1], labels[alg2]))), \"\\\\\\\\ \\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algs = pd.DataFrame(columns = algs, index=algs)\n",
    "for alg1, alg2 in zip([\"topsbm\", \"topsbm\", \"topsbm\", \"topsbm\", \"tm\", \"tm\", \"tm\", \"lda\", \"lda\", \"wgcna\"],[\"tm\",\"lda\", \"wgcna\", \"hierarchical-log\", \"lda\", \"wgcna\", \"hierarchical-log\", \"wgcna\", \"hierarchical-log\", \"hierarchical-log\"]):\n",
    "    df_algs.at[alg1,alg2]=float(v_measure_score(labels[alg1], labels[alg2]))\n",
    "    \n",
    "df_algs.at[\"tm\", \"topsbm\"]=0.256\n",
    "df_algs.at[\"lda\", \"topsbm\"]=0.051\n",
    "df_algs.at[\"wgcna\", \"topsbm\"]=0.058\n",
    "df_algs.at[\"lda\", \"tm\"]=0.264\n",
    "df_algs.at[\"wgcna\", \"tm\"]=0.656\n",
    "df_algs.at[\"wgcna\", \"lda\"]=0.175\n",
    "import seaborn as sns\n",
    "\n",
    "cm = sns.clustermap(df_algs.fillna(0.5), vmin=0, vmax=1, row_cluster=False, \n",
    "                    col_cluster=False,\n",
    "                   cmap = sns.diverging_palette(240, 10, sep=20, as_cmap=True))\n",
    "ax = cm.ax_heatmap\n",
    "fig = ax.get_figure()\n",
    "ax.set_yticklabels(labels=algs, rotation=0)\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "ax.set_xticklabels(labels=algs, rotation=90)\n",
    "ax.tick_params(labelsize=35)\n",
    "\n",
    "ax.text(1,4,\"topics\", fontsize=35, color=\"black\", rotation = 360-45)\n",
    "ax.text(2.5,2,\"clusters\", fontsize=35, color=\"black\", rotation = 360-45)\n",
    "\n",
    "\n",
    "cax = cm.ax_cbar\n",
    "cax.tick_params(labelsize=30)\n",
    "cax.set_title(\"$NMI$\", fontsize=30)\n",
    "plt.tight_layout()\n",
    "cm.savefig(f\"{directory}/comparisons.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
