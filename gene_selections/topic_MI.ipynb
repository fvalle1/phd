{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from scipy.stats import entropy, hypergeom\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/jovyan/work/phd/gene_selections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from entropy import get_entropy, get_array_entropy\n",
    "from overlap import get_overlap, get_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../keywordTCGA/brca/\"\n",
    "#directory = \"../triText/APS/\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-jesus",
   "metadata": {},
   "source": [
    "## KL-div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = pd.read_csv(\"topsbm/topsbm_level_2_topic-dist.csv\", index_col=1).drop(\"i_doc\", 1)\n",
    "df_first = df_first.divide(df_first.sum(0),1)\n",
    "\n",
    "df_second = pd.read_csv(\"trisbm/trisbm_level_1_metadatum-dist.csv\", index_col=1).drop(\"i_doc\", 1)\n",
    "\n",
    "#same subset of stuff\n",
    "assert((~df_first.index.isin(df_second.index)).sum()==0)\n",
    "assert((~df_second.index.isin(df_first.index)).sum()==0)\n",
    "\n",
    "df_second = df_second.reindex(index=df_first.index)\n",
    "df_second = df_second.divide(df_second.sum(0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-metro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first = tf.convert_to_tensor(df_first.fillna(0).values.T, dtype=tf.float64)\n",
    "second = tf.convert_to_tensor(df_second.fillna(0).values.T, dtype=tf.float64)\n",
    "kld_matrix = get_array_entropy(first, second).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.clustermap(kld_matrix,\n",
    "            xticklabels=df_second.columns,\n",
    "            yticklabels=df_first.columns,\n",
    "            row_cluster=False,\n",
    "            col_cluster=False)\n",
    "\n",
    "ax = cm.ax_heatmap\n",
    "fig = ax.get_figure()\n",
    "ax.set_ylabel(\"hSBM\", fontsize=35, rotation=90)\n",
    "ax.set_xlabel(\"trisbm\", fontsize=35, rotation=90)\n",
    "\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "ax.tick_params(labelsize=35)\n",
    "\n",
    "cax = cm.ax_cbar\n",
    "cax.tick_params(labelsize=30)\n",
    "cax.set_title(\"KL-div\", fontsize=30)\n",
    "cm.savefig(f\"topic_kl.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-preliminary",
   "metadata": {},
   "source": [
    "## Cluster conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = pd.read_csv(\"topsbm/topsbm_level_2_clusters.csv\")\n",
    "df_second = pd.read_csv(\"trisbm/trisbm_level_0_clusters.csv\")\n",
    "assert(np.isin(list(filter(lambda sample: str(sample)!=\"nan\",df_first.values.ravel())), \n",
    "        list(filter(lambda sample: str(sample)!=\"nan\",df_second.values.ravel())), invert=True).sum()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_first.values.ravel()\n",
    "samples = list(filter(lambda sample: str(sample)!=\"nan\",samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = []\n",
    "for sample in samples:\n",
    "    partition.append((\n",
    "            df_first.columns[(df_first==sample).any()].values[0].split(\" \")[1],\n",
    "            df_second.columns[(df_second==sample).any()].values[0].split(\" \")[1]\n",
    "            )\n",
    "        )\n",
    "partition = list(zip(*partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(partition[0],partition[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_overlap = pd.DataFrame(index=df_first.columns, columns=df_second.columns, data=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap(x,y):\n",
    "    return np.isin(x,y).sum()\n",
    "\n",
    "def get_pval(setA, setB):\n",
    "    x = np.isin(setA,setB).sum() # number of successes\n",
    "    M = len(samples) # pop size\n",
    "    k = len(setB) # successes in pop\n",
    "    N = len(setA) # sample size\n",
    "    pval = hypergeom.sf(x-1, M, k, N)\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_first.columns:\n",
    "    for column in df_second.columns:\n",
    "        df_cluster_overlap.at[row,column]=get_overlap(df_first[row].dropna().values, df_second[column].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_cluster_overlap,\n",
    "           #vmax=100\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-allergy",
   "metadata": {},
   "source": [
    "## Topic conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = pd.read_csv(\"topsbm/topsbm_level_2_topics.csv\")\n",
    "df_second = pd.read_csv(\"trisbm/trisbm_level_1_topics.csv\")\n",
    "assert(np.isin(list(filter(lambda sample: str(sample)!=\"nan\",df_first.values.ravel())), \n",
    "        list(filter(lambda sample: str(sample)!=\"nan\",df_second.values.ravel())), invert=True).sum()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = df_first.values.ravel()\n",
    "genes = list(filter(lambda sample: str(sample)!=\"nan\",genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = []\n",
    "for sample in genes:\n",
    "    partition.append((\n",
    "        df_first.columns[(df_first==sample).any()].values[0].split(\" \")[1],\n",
    "        df_second.columns[(df_second==sample).any()].values[0].split(\" \")[1]\n",
    "        )\n",
    "    )\n",
    "partition = list(zip(*partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(partition[0],partition[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_overlap = pd.DataFrame(index=df_first.columns, columns=df_second.columns, data=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_first.columns:\n",
    "    for column in df_second.columns:\n",
    "        df_cluster_overlap.at[row,column]=get_overlap(df_first[row].dropna().values, df_second[column].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_cluster_overlap,\n",
    "           vmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-monday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}