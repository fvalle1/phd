{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM7BoWVULIgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ0Axhw2Hfop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys, gc\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append(\"/content/drive/My Drive/phd\")\n",
        "sys.path.append(\"/content/drive/My Drive/phd/hsbm-occam\")\n",
        "from hsbmpy import get_max_available_L\n",
        "\n",
        "os.environ[\"TF_CUDNN_USE_AUTOTUNE\"]=\"0\" #to avoid Nvidia GPU warming up"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhh35xNYHfo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "algorithm = \"topsbm\"\n",
        "directory='/content/drive/My Drive/phd/datasets/merged'\n",
        "L = get_max_available_L(directory, algorithm)-2\n",
        "os.chdir(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXZfXhOYHfo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = 'primary_site'\n",
        "\n",
        "df_topics = pd.read_csv(\"%s/%s_level_%d_topic-dist.csv\"%(algorithm,algorithm,L)).set_index('doc').drop('i_doc', axis=1)\n",
        "df_words = pd.read_csv(\"%s/%s_level_%d_word-dist.csv\"%(algorithm,algorithm,L), index_col=0)\n",
        "df_words.index=[g[:15] for g in df_words.index]\n",
        "df = pd.read_csv(\"mainTable.csv\", index_col=0).reindex(index=df_words.index)\n",
        "df = df.divide(df.sum(0),1).transpose().fillna(0)\n",
        "df_files=pd.read_csv(\"files.dat\", index_col=0)\n",
        "df_topics.insert(0,'tissue', df_files.reindex(index=df_topics.index)[label])\n",
        "df_topic_tissue = df_topics.groupby('tissue').mean()\n",
        "df_files.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdnogDbsHfpP",
        "colab_type": "text"
      },
      "source": [
        "## Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB8z21PkHfpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import binary_crossentropy,mean_squared_error, categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.client.device_lib import list_local_devices\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os,sys, gc\n",
        "list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8SmE2OrHfpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_labels=df_files.copy()\n",
        "df_labels=df_labels.reindex(index=df_topics.index)\n",
        "\n",
        "uniq = len(df_labels[label].unique())\n",
        "\n",
        "X_train = df_topics.drop('tissue',1)\n",
        "X_train = X_train.subtract(X_train.mean(0),1).divide(0.5*(X_train.max(0)-X_train.min(0)),1).values.astype(float) #SGD transform\n",
        "Y_train = to_categorical(np.unique(df_labels[label], return_inverse=True)[1])\n",
        "inputs = X_train.shape[1]\n",
        "\n",
        "if uniq==2: #hidden=(1941,100), bs=50 \n",
        "  Y_train = np.argmax(Y_train, axis=-1)\n",
        "  uniq = 1\n",
        "  activation_func = \"sigmoid\"\n",
        "  lr = 0.01\n",
        "  bs = 50\n",
        "  momentum = 0.9\n",
        "  l1 = 0.01\n",
        "  l2 = 0.0001\n",
        "  loss=binary_crossentropy\n",
        "else: #hidden (1941,100), bs=500, l1=0.001, l2=1e-9\n",
        "  activation_func = \"softmax\"\n",
        "  lr = 0.03\n",
        "  bs = 500\n",
        "  momentum = 0.95\n",
        "  l1 = 0.001\n",
        "  l2 = 1e-9\n",
        "  loss=categorical_crossentropy\n",
        "\n",
        "\n",
        "classes=np.unique(df_labels[df_labels.index.isin(df.index)][label], return_inverse=True)[0]\n",
        "\n",
        "X_tm_train, X_tm_test, Y_tm_train, Y_tm_test = train_test_split(X_train, Y_train, random_state=42, train_size=0.95)\n",
        "\n",
        "print(uniq, X_train.shape, Y_train.shape, X_tm_train.shape, Y_tm_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUGhPlOCA3UE",
        "colab_type": "text"
      },
      "source": [
        "# projections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8FrrIgKBq2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "class ProjectorClassifier():\n",
        "    def __init__(self):\n",
        "        self.labels = None\n",
        "        self._isfitted = False\n",
        "        self._entropy = tf.keras.losses.KLDivergence()\n",
        "        #self._entropy = tf.keras.losses.MeanSquaredError()\n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "        classes, _ = tf.unique(Y)\n",
        "        self.labels = tf.map_fn(lambda c: tf.reduce_mean(tf.boolean_mask(X,tf.equal(Y, tf.repeat(c, tf.constant(Y.shape[0], dtype=tf.int64)))), axis=0), classes, dtype=tf.float64)\n",
        "        self._isfitted = True\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self._isfitted:\n",
        "            raise ValueError(\"Call Projector.fit() first\")\n",
        "        predictions = tf.argmin(tf.map_fn(lambda label: tf.map_fn(lambda x: self._entropy(x, label), X), self.labels), axis=0)\n",
        "        return predictions\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        if not self._isfitted:\n",
        "            raise ValueError(\"Call Projector.fit() first\")\n",
        "        Y_pred = self.predict(X)\n",
        "        if tf.reduce_max(Y) > tf.constant(1, dtype=tf.int64):\n",
        "            Y = to_categorical(Y)\n",
        "            Y_pred = to_categorical(Y_pred)\n",
        "        acc = accuracy_score(Y, Y_pred)\n",
        "        auc = roc_auc_score(Y, Y_pred, average=\"weighted\", multi_class=\"ovr\")\n",
        "        print(f\"Accuracy: {acc}, AUC:{auc}\")\n",
        "        return [acc, auc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDqsKfcwBqpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.convert_to_tensor(df_topics.drop('tissue',1))\n",
        "Y = tf.convert_to_tensor(Y_train)\n",
        "\n",
        "#X_pj_train, X_pj_test, Y_pj_train, Y_pj_test = train_test_split(X.numpy(), Y.numpy(), random_state=42, train_size=0.8)\n",
        "#Y_pj_train = tf.argmax(Y_pj_train, 1)\n",
        "#Y_pj_test = tf.argmax(Y_pj_test, 1)\n",
        "\n",
        "#X_pj_train, X_pj_test, Y_pj_train, Y_pj_test = train_test_split(df.values, np.unique(df_files.reindex(index=df.index)[label], return_inverse=True)[1], random_state=42, train_size=0.8)\n",
        "X_pj_train, X_pj_test, Y_pj_train, Y_pj_test = train_test_split(pd.read_csv(\"mainTable.csv\", index_col=0).reindex(index=df_words.index).fillna(0).applymap(lambda tpm: np.log2(tpm+1)).values.T, np.unique(df_files.reindex(index=df.index)[label], return_inverse=True)[1], random_state=42, train_size=0.8)\n",
        "\n",
        "X_pj_train, X_pj_test, Y_pj_train, Y_pj_test = list(map(tf.convert_to_tensor, (X_pj_train, X_pj_test, Y_pj_train, Y_pj_test)))\n",
        "print(uniq, X_pj_train.shape, Y_pj_train.shape, X_pj_test.shape, Y_pj_test.shape, Y_pj_train[0])\n",
        "\n",
        "import time\n",
        "\n",
        "with tf.device(\"GPU\"):\n",
        "    model_proj = ProjectorClassifier()\n",
        "    model_proj.fit(X_pj_train, Y_pj_train)\n",
        "    model_proj.evaluate(X_pj_test, Y_pj_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cu0QRGFA9XQ",
        "colab_type": "text"
      },
      "source": [
        "# K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEsVBf7sA21e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "class KNNClassifier(KNeighborsClassifier):\n",
        "    def __init__(self, n_neighbors=10, **kwargs):\n",
        "        super().__init__(n_neighbors, **kwargs)\n",
        "\n",
        "    def fit(self,  X, y):\n",
        "        return super().fit(X, y)\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        Y_pred = self.predict(X)\n",
        "        if tf.reduce_max(Y) > tf.constant(1, dtype=tf.int64):\n",
        "            Y = to_categorical(Y)\n",
        "            Y_pred = to_categorical(Y_pred)\n",
        "        acc = accuracy_score(Y, Y_pred)\n",
        "        auc = roc_auc_score(Y, Y_pred, average=\"weighted\", multi_class=\"ovr\")\n",
        "        print(f\"Accuracy: {acc}, AUC:{auc}\")\n",
        "        return [acc, auc]\n",
        "\n",
        "    \n",
        "#X_knn_train, X_knn_test, Y_knn_train, Y_knn_test = train_test_split(X.numpy(), Y.numpy(), random_state=42, train_size=0.8)\n",
        "#Y_knn_train = tf.argmax(Y_knn_train, 1)\n",
        "#Y_knn_test = tf.argmax(Y_knn_test, 1)\n",
        "\n",
        "#X_knn_train, X_knn_test, Y_knn_train, Y_knn_test = train_test_split(df.values, np.unique(df_files.reindex(index=df.index)[label], return_inverse=True)[1], random_state=42, train_size=0.8)\n",
        "X_knn_train, X_knn_test, Y_knn_train, Y_knn_test = train_test_split(pd.read_csv(\"mainTable.csv\", index_col=0).reindex(index=df_words.index).fillna(0).applymap(lambda tpm: np.log2(tpm+1)).values.T, np.unique(df_files.reindex(index=df.index)[label], return_inverse=True)[1], random_state=42, train_size=0.8)\n",
        "\n",
        "X_pj_train, X_pj_test, Y_pj_train, Y_pj_test = list(map(tf.convert_to_tensor, (X_knn_train, X_knn_test, Y_knn_train, Y_knn_test)))\n",
        "print(uniq, X_knn_train.shape, Y_knn_train.shape, X_knn_test.shape, Y_knn_test.shape, Y_knn_train[0])\n",
        "import time\n",
        "with tf.device(\"GPU\"):\n",
        "    model_knn = KNNClassifier(n_neighbors=5, n_jobs=4, metric=\"euclidean\")\n",
        "    model_knn.fit(X_knn_train, Y_knn_train)\n",
        "    model_knn.evaluate(X_knn_test, Y_knn_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdVNVDc3A5yS",
        "colab_type": "text"
      },
      "source": [
        "#Â Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A-pjO9lHfpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "os.system(\"rm -rf log.csv\")\n",
        "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, mode='min', patience=25)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(units=100, input_dim=inputs, use_bias=True, bias_initializer=\"ones\", activation=\"relu\", kernel_regularizer=l1_l2(l1=l1, l2=l2)))\n",
        "model.add(Dense(units=uniq, activation=activation_func))\n",
        "model.compile(loss=loss, optimizer=SGD(lr=lr, momentum=momentum), metrics=['accuracy', 'AUC'])\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "print(model.summary())\n",
        "plot_model(model, to_file=f\"model_{label}.png\", dpi=600, show_shapes=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHvt7jFHfpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device(\"GPU\"):\n",
        "    model.fit(X_tm_train, Y_tm_train, epochs=1000, batch_size=bs, verbose=1, validation_split=0.25, callbacks=[csv_logger, es], shuffle=True, use_multiprocessing=True, workers=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANz0bgi2Hfpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv(\"log.csv\", sep=\",\")[['loss','val_loss']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie8qRsmeHfpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_tm_test, Y_tm_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcwyj17QHfpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(f\"model_{label}.h5\")\n",
        "#model = load_model(f\"model_{label}.h5\")\n",
        "#print(model.summary())\n",
        "#plot_model(model, to_file=f\"model_{label}.png\", dpi=600, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFyBghA0Hfpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIWNWHbwHfpz",
        "colab_type": "text"
      },
      "source": [
        "# evaluate on non used on topsbm training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFz-Y-xXHfp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_table = pd.read_csv(\"mainTable_test.csv\", index_col = 0)\n",
        "df_test_table = df_test_table.where(df_test_table<1e5,1e5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDydAbSeHfp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get only HV genes\n",
        "df_topic_test = df_test_table.reindex(index=df_words.index)\n",
        "df_topic_test = df_topic_test.transpose().fillna(-1).astype(int)\n",
        "\n",
        "df_topic_test = pd.DataFrame(data=np.matmul(df_topic_test.values,df_words.values), index=df_topic_test.index, columns=df_words.columns)\n",
        "df_test=df_topic_test.divide(df_topic_test.mean(axis=0), axis=1) #normalize P(t|d)\n",
        "\n",
        "df_test = df_test.subtract(df_topics.drop(\"tissue\",1).mean(0),1).divide((X_train.max(0)-X_train.min(0)),1) #SGD transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j79SHXWDHfp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = np.unique(df_files.reindex(index=df_test.index)[label])\n",
        "X_test = df_test.values.astype(float)\n",
        "Y_test = to_categorical([np.where(classes==t)[0][0] for t in df_files.reindex(index=df_test.index)[label].values.ravel()])\n",
        "if uniq==1:\n",
        "  Y_test = np.argmax(Y_test, axis=-1)\n",
        "  uniq=1\n",
        "#np.savetxt(\"classes.txt\", classes, fmt=\"%s\")\n",
        "#np.savetxt(\"X_test.txt\", X_test)\n",
        "#np.savetxt(\"Y_test.txt\", Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JLmv_InHfp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device(\"GPU\"):\n",
        "    model.evaluate(X_test, Y_test, verbose=2, workers=-1, use_multiprocessing=True)\n",
        "    if uniq ==1:\n",
        "        model_proj.evaluate(tf.convert_to_tensor(df_topic_test), tf.convert_to_tensor(Y_test))\n",
        "        model_knn.evaluate(tf.convert_to_tensor(df_topic_test), tf.convert_to_tensor(Y_test))\n",
        "    else:\n",
        "        model_proj.evaluate(tf.convert_to_tensor(df_topic_test), tf.argmax(tf.convert_to_tensor(Y_test), axis = 1))\n",
        "        model_knn.evaluate(tf.convert_to_tensor(df_topic_test), tf.argmax(tf.convert_to_tensor(Y_test), axis = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuS52Or_j_im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdOMEPwJkKT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_p = model.predict(X_test)\n",
        "if uniq>1:\n",
        "  y_true = np.argmax(Y_test,axis=-1)\n",
        "  y_pred = np.argmax(y_pred_p,axis=-1)\n",
        "else:\n",
        "  y_pred_p = y_pred_p.ravel()\n",
        "  y_true = Y_test\n",
        "  y_pred = np.ones(y_pred_p.shape)\n",
        "  y_pred[y_pred_p<0.5]=0\n",
        "results = confusion_matrix(y_true, y_pred, normalize=\"true\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMC0y97WHfqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = sns.clustermap(results, \n",
        "                    vmax=1,  \n",
        "                    row_cluster=False, \n",
        "                    col_cluster=False, \n",
        "                    xticklabels=classes, \n",
        "                    yticklabels=classes, \n",
        "                    annot=False,\n",
        "                    annot_kws={\"fontsize\":15},\n",
        "                    cbar_pos=(0.99,0.05,0.05,0.7))\n",
        "ax = cm.ax_heatmap\n",
        "fig = ax.get_figure()\n",
        "ax.set_ylabel(\"real\", fontsize=35, rotation=90)\n",
        "ax.set_yticklabels(labels=classes, rotation=0)\n",
        "ax.yaxis.tick_left()\n",
        "ax.yaxis.set_label_position(\"left\")\n",
        "\n",
        "ax.set_xticklabels(labels=classes, rotation=80)\n",
        "ax.set_xlabel(\"predicted\",fontsize=35)\n",
        "ax.tick_params(labelsize=35)\n",
        "\n",
        "cax = cm.ax_cbar\n",
        "cax.tick_params(labelsize=30)\n",
        "cax.set_title(\"P()\", fontsize=30)\n",
        "plt.tight_layout()\n",
        "cm.savefig(f\"predict_{label}.pdf\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_T2el1pHfqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax= plt.subplots(figsize=(18,15))\n",
        "\n",
        "if uniq > 1:\n",
        "  for c in range(uniq):\n",
        "    ax.hist((1-model.predict(X_test).T[0])[Y_test.argmax(1)==c], histtype=\"step\", lw=15, bins=10, density=True)\n",
        "else:\n",
        "  ax.hist(y_pred_p[Y_test==1], histtype=\"step\", lw=15, bins=10, density=False, label=\"healthy\")\n",
        "  ax.hist(y_pred_p[Y_test==0], histtype=\"step\", lw=15, bins=10, density=False, label=\"tumor\")\n",
        "\n",
        "ax.tick_params(labelsize=35)\n",
        "ax.legend(fontsize=35, loc=\"upper left\")\n",
        "ax.set_title(\"\", fontsize=35)\n",
        "\n",
        "ax.set_xlim(-0.05,1.05)\n",
        "\n",
        "ax.set_xlabel(\"Z\", fontsize=35)\n",
        "ax.set_ylabel(\"pdf\", fontsize=35)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc5dF_kK-8YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_p)\n",
        "#fpr, tpr, thresholds = roc_curve(Y_train, model.predict(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F92ZJJ1vWVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(18,15))\n",
        "\n",
        "ax.plot(fpr,tpr, c=\"gray\", lw=15)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=15)\n",
        "ax.set_xlabel('False positive rate', fontsize=35)\n",
        "ax.set_ylabel('True positive rate', fontsize=35)\n",
        "\n",
        "\n",
        "for f, t, thr in zip(fpr[::100], tpr[::100], thresholds[::100]):\n",
        "    ax.annotate(thr, (f, t), fontsize=25)\n",
        "\n",
        "ax.annotate(\"Area Under Curve = %.4f\"%roc_auc_score(y_true, y_pred_p), xy=(0.6, 0.5), fontsize=25)\n",
        "\n",
        "ax.tick_params(labelsize=35)\n",
        "\n",
        "plt.show()\n",
        "fig.savefig(f\"roc_{label}.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPwa8oHnMpRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,18))\n",
        "for itissue, tissue in enumerate(classes):\n",
        "  tissue_true = y_true.copy()\n",
        "  tissue_true[y_true==itissue]=1\n",
        "  tissue_true[y_true!=itissue]=0\n",
        "  fpr, tpr, thresholds = roc_curve(tissue_true, y_pred_p.T[itissue])\n",
        "\n",
        "  ax.plot(fpr,tpr, lw=15, alpha=0.8)\n",
        "\n",
        "  ax.plot([0, 1], [0, 1], 'k--', lw=15)\n",
        "  ax.set_xlabel('False positive rate', fontsize=35)\n",
        "  ax.set_ylabel('True positive rate', fontsize=35)\n",
        "\n",
        "  ax.tick_params(labelsize=35)\n",
        "\n",
        "ax.set_ylim(0.8,1)\n",
        "plt.show()\n",
        "fig.savefig(f\"roc_{label}.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecz4ARzeDn9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}