{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys, gc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "sys.path.append(\"/content/drive/My Drive/phd/\")\n",
    "sys.path.append(\"/content/drive/My Drive/phd/master_thesis/hsbm/\")\n",
    "from hsbmpy import get_max_available_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = 'disease_type'\n",
    "algorithm = \"topsbm\"\n",
    "directory='/content/drive/My Drive/phd/datasets/merged'\n",
    "L = get_max_available_L(directory, algorithm)-2\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'status'\n",
    "\n",
    "df_topics = pd.read_csv(\"%s/%s_level_%d_topic-dist.csv\"%(algorithm,algorithm,L)).set_index('doc').drop('i_doc', axis=1)\n",
    "df_words = pd.read_csv(\"%s/%s_level_%d_word-dist.csv\"%(algorithm,algorithm,L), index_col=0)\n",
    "df_words.index=[g[:15] for g in df_words.index]\n",
    "df = pd.read_csv(\"mainTable.csv\", index_col=0).reindex(index=df_words.index)\n",
    "df = df.divide(df.sum(0),1).transpose().fillna(0)\n",
    "df_files=pd.read_csv(\"files.dat\", index_col=0)\n",
    "df_topics.insert(0,'tissue', df_files.reindex(index=df_topics.index)[label])\n",
    "df_topic_tissue = df_topics.groupby('tissue').mean()\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pst = pd.DataFrame(data=pd.np.matmul(df.values,df_words.values), index= df.index, columns=df_words.columns)\n",
    "df_Pst = df_Pst.subtract(df_Pst.mean(1), 0)\n",
    "predictions = pd.np.array(list(map(lambda x: list(map(lambda y: entropy(x, y), df_topic_tissue.astype(float).values)), df_Pst.astype(float).values)))\n",
    "\n",
    "df_Pst.insert(0,'tissue', df_files.reindex(index=df_Pst.index)[label])\n",
    "reals = pd.np.unique(df_Pst.tissue, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(reals, pd.np.argmin(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN based predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution1D\n",
    "from tensorflow.keras.losses import binary_crossentropy,mean_squared_error, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import plot_model,to_categorical\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.client.device_lib import list_local_devices\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import os,sys, gc\n",
    "list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=df_files.copy()\n",
    "df_labels=df_labels.reindex(index=df_topics.index)\n",
    "\n",
    "uniq = len(df_labels[label].unique())\n",
    "\n",
    "X_train = df_topics.drop('tissue',1)\n",
    "X_train = X_train.subtract(X_train.mean(0),1).divide(0.5*(X_train.max(0)-X_train.min(0)),1).values.astype(float) #SGD transform\n",
    "Y_train = to_categorical(np.unique(df_labels[label], return_inverse=True)[1])\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "if uniq==2:\n",
    "  Y_train = np.abs((np.argmax(Y_train, axis=-1)-1)) #1=\"healthy\"\n",
    "  uniq = 1\n",
    "  activation_func = \"sigmoid\"\n",
    "  lr = 0.01\n",
    "  momentum = 0.9\n",
    "  l1 = 0.01\n",
    "  l2 = 0.0001\n",
    "  loss=binary_crossentropy\n",
    "else:\n",
    "  activation_func = \"softmax\"\n",
    "  lr = 0.003\n",
    "  momentum = 0.95\n",
    "  l1 = 0.001\n",
    "  l2 = 0\n",
    "  loss=categorical_crossentropy\n",
    "\n",
    "\n",
    "classes=np.unique(df_labels[df_labels.index.isin(df.index)][label], return_inverse=True)[0]\n",
    "\n",
    "X_tm_train, X_tm_test, Y_tm_train, Y_tm_test = train_test_split(X_train, Y_train, random_state=42, train_size=0.95)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_tm_train.shape, Y_tm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "os.system(\"rm -rf log.csv\")\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, mode='min', patience=25)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=100, input_dim=inputs, use_bias=True, bias_initializer=\"ones\", activation=\"relu\", kernel_regularizer=l1_l2(l1=0.01, l2=0.0001)))\n",
    "model.add(Dense(units=uniq, activation=activation_func))\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr, momentum=momentum), metrics=['accuracy', 'AUC'])\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file=f\"model_{label}.png\", dpi=600, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"GPU\"):\n",
    "    model.fit(X_tm_train, Y_tm_train, epochs=1000, batch_size=500, verbose=1, validation_split=0.25, callbacks=[csv_logger, es], shuffle=True, use_multiprocessing=True, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"log.csv\", sep=\",\")[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_tm_test, Y_tm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"model_{label}.h5\")\n",
    "#model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate on non used on topsbm training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_table = pd.read_csv(\"mainTable_test.csv\", index_col = 0)\n",
    "df_test_table = df_test_table.where(df_test_table<1e5,1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only HV genes\n",
    "df_test = df_test_table.reindex(index=df_words.index)\n",
    "df_test = df_test.transpose().fillna(-1).astype(int)\n",
    "\n",
    "df_test = pd.DataFrame(data=np.matmul(df_test.values,df_words.values), index=df_test.index, columns=df_words.columns)\n",
    "df_test=df_test.divide(df_test.mean(axis=0), axis=1) #normalize P(t|d)\n",
    "\n",
    "df_test = df_test.subtract(df_topics.drop(\"tissue\",1).mean(0),1).divide((X_train.max(0)-X_train.min(0)),1) #SGD transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(df_files.reindex(index=df_test.index)[label])\n",
    "X_test = df_test.values.astype(float)\n",
    "Y_test = to_categorical([np.where(classes==t)[0][0] for t in df_files.reindex(index=df_test.index)[label].values.ravel()])\n",
    "if uniq==1:\n",
    "  Y_test = np.abs(np.argmax(Y_test, axis=-1)-1)\n",
    "  uniq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=2, workers=-1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = model.predict(X_test)\n",
    "if uniq>1:\n",
    "  y_true = np.argmax(Y_test,axis=-1)\n",
    "  y_pred = np.argmax(y_pred_p,axis=-1)\n",
    "else:\n",
    "  y_true = Y_test\n",
    "  y_pred = np.ones(y_pred_p.shape)\n",
    "  y_pred[y_pred_p<0.8]=0\n",
    "results = confusion_matrix(y_true, y_pred, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.clustermap(results, \n",
    "                    vmax=1,  \n",
    "                    row_cluster=False, \n",
    "                    col_cluster=False, \n",
    "                    xticklabels=classes, \n",
    "                    yticklabels=classes, \n",
    "                    annot=False,\n",
    "                    annot_kws={\"fontsize\":25},\n",
    "                    cbar_pos=(0.99,0.05,0.05,0.7))\n",
    "ax = cm.ax_heatmap\n",
    "fig = ax.get_figure()\n",
    "ax.set_ylabel(\"real\", fontsize=35, rotation=90)\n",
    "ax.set_yticklabels(labels=classes, rotation=0)\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "ax.set_xticklabels(labels=classes, rotation=45)\n",
    "ax.set_xlabel(\"predicted\",fontsize=35)\n",
    "ax.tick_params(labelsize=35)\n",
    "\n",
    "cax = cm.ax_cbar\n",
    "cax.tick_params(labelsize=30)\n",
    "cax.set_title(\"P()\", fontsize=30)\n",
    "plt.tight_layout()\n",
    "cm.savefig(f\"predict_{label}.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize=(18,15))\n",
    "\n",
    "if uniq > 1:\n",
    "  for c in range(uniq):\n",
    "    ax.hist((1-model.predict(X_test).T[0])[Y_test.argmax(1)==c], histtype=\"step\", lw=15, bins=10, density=True)\n",
    "else:\n",
    "  ax.hist(y_pred_p[Y_test==1], histtype=\"step\", lw=15, bins=10, density=False, label=\"healthy\")\n",
    "  ax.hist(y_pred_p[Y_test==0], histtype=\"step\", lw=15, bins=10, density=False, label=\"tumor\")\n",
    "\n",
    "ax.tick_params(labelsize=35)\n",
    "ax.legend(fontsize=35, loc=\"upper left\")\n",
    "ax.set_title(\"\", fontsize=35)\n",
    "\n",
    "ax.set_xlim(-0.05,1.05)\n",
    "\n",
    "ax.set_xlabel(\"Z\", fontsize=35)\n",
    "ax.set_ylabel(\"pdf\", fontsize=35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_p.T[0])\n",
    "#fpr, tpr, thresholds = roc_curve(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "\n",
    "ax.plot(fpr,tpr, c=\"gray\", lw=15)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=15)\n",
    "ax.set_xlabel('False positive rate', fontsize=35)\n",
    "ax.set_ylabel('True positive rate', fontsize=35)\n",
    "\n",
    "\n",
    "for f, t, thr in zip(fpr[::100], tpr[::100], thresholds[::100]):\n",
    "    ax.annotate(thr, (f, t), fontsize=25)\n",
    "\n",
    "ax.annotate(\"Area Under Curve = %.4f\"%roc_auc_score(y_true, y_pred_p.T[0]), xy=(0.6, 0.5), fontsize=25)\n",
    "\n",
    "ax.tick_params(labelsize=35)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"roc_{label}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,18))\n",
    "for itissue, tissue in enumerate(classes):\n",
    "  tissue_true = y_true.copy()\n",
    "  tissue_true[y_true==itissue]=1\n",
    "  tissue_true[y_true!=itissue]=0\n",
    "  fpr, tpr, thresholds = roc_curve(tissue_true, y_pred_p.T[itissue])\n",
    "\n",
    "  ax.plot(fpr,tpr, lw=15, alpha=0.8)\n",
    "\n",
    "  ax.plot([0, 1], [0, 1], 'k--', lw=15)\n",
    "  ax.set_xlabel('False positive rate', fontsize=35)\n",
    "  ax.set_ylabel('True positive rate', fontsize=35)\n",
    "\n",
    "  ax.tick_params(labelsize=35)\n",
    "\n",
    "ax.set_ylim(0.8,1)\n",
    "plt.show()\n",
    "fig.savefig(f\"roc_{label}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
