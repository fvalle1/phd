{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, gc\n",
    "os.chdir(\"/home/jovyan/work/phd/datasets/gtex/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"mainTable.csv\", index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\",'w') as file:\n",
    "    for sample in df.columns:\n",
    "        for g in np.array(df[sample].sort_values(ascending=False).index[:1000],dtype=str):\n",
    "            file.write(g[:15])\n",
    "            file.write(\" \")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"export PATH=$PATH:/home/jovyan/work/phd/topicmapping/bin\")\n",
    "os.system(\"topicmap -f corpus.txt -r 10 -t 10 -seed 42 -o tm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.read_csv(\"tm/word_wn_count.txt\", sep=' ', header=None)\n",
    "df_words.columns=['word', 'word-id', 'occurrence']\n",
    "df_words.sort_values('word-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distr = pd.read_csv(\"tm/lda_gammas_final.txt\", sep=' ', header=None)\n",
    "df_topic_distr.columns=['Topic %d'%(t+1) for t in df_topic_distr.columns]\n",
    "df_topic_distr.index.name='i_doc'\n",
    "df_topic_distr.insert(0,'doc',df.columns)\n",
    "df_topic_distr=df_topic_distr.dropna(how='all',axis=1)\n",
    "df_topic_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = df_topic_distr.drop('doc',1).values.argmax(1)\n",
    "df_clusters=pd.DataFrame()\n",
    "for cluster in range(np.max(clusters)+1):\n",
    "    elems=df.columns[clusters==cluster].values\n",
    "    df_clusters.insert(0,'Cluster %d'%(cluster+1),np.concatenate([elems, ['' for _ in range(len(df.columns)- len(elems))]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.sort_index(axis=1).to_csv(\"tm/tm_level_0_clusters.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distr.to_csv(\"tm/tm_level_0_topic-dist.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_distr = pd.DataFrame().fillna(0)\n",
    "with open(\"tm/lda_betas_sparse_final.txt\",\"r\") as f:\n",
    "    for line in f.read().split(\"\\n\"):\n",
    "        row = line.split(\" \")\n",
    "        if len(row) < 2:\n",
    "            continue\n",
    "        topic = int(row[0])+1\n",
    "        line=np.array(row[1:-1], dtype=float).reshape(int((len(row)-1)/2),2)\n",
    "        for el in line:\n",
    "            df_word_distr.at[df_words[df_words['word-id']==int(el[0])].word.values[0], f\"Topic {topic}\"] = el[1]\n",
    "#df_word_distr.index=df_words['word']\n",
    "df_word_distr.fillna(0)\n",
    "df_word_distr.to_csv(\"tm/tm_level_0_word-dist.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.DataFrame()\n",
    "max_L = df_word_distr.shape[0]\n",
    "for topic in df_word_distr.columns[::-1]:\n",
    "    t_series = df_word_distr[topic]\n",
    "    t_series = t_series[t_series>t_series.quantile(0.99)]\n",
    "    df_topics.insert(0,topic,np.concatenate((t_series.index.values,np.repeat(np.nan, df_word_distr.shape[0]-len(t_series)))))\n",
    "df_topics.dropna(how=\"all\", axis=0).to_csv(\"tm/tm_level_0_topics.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
