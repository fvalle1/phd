{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hopfield4py import Hopfield\n",
    "from hopfield4py.hopfield_helper import *\n",
    "import tensorflow as tf\n",
    "from topicpy import gtex\n",
    "import multiprocessing as mp\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../cancers/breast/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{directory}/topsbm/topsbm_level_0_topic-dist.csv', index_col=1).drop(\"i_doc\", axis=1)\n",
    "df=df.transpose().reset_index()\n",
    "df.rename({\"index\":\"id\"}, axis=1, inplace=True)\n",
    "#df.set_index(\"id\", inplace=True)\n",
    "df = df.set_index(\"id\").transpose()\n",
    "#df = df.subtract(df.mean(axis=0),1).abs().divide(df.std(axis=0),1) ## DNW\n",
    "df = df.subtract(df.min(axis=0),1).abs().divide(df.max(axis=0)-df.min(axis=0),1) ## threshold should be 0.005\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_series(s: pd.Series):\n",
    "    new = s.copy()\n",
    "    q1, q2 = s.quantile(q=[0.45,0.55])\n",
    "    new[new<q1] = -1\n",
    "    new[new>q2] = 1\n",
    "    new[(new >= q1) & (new <= q2)] = 0\n",
    "    return new.astype(int)\n",
    "\n",
    "#df = df.apply(refactor_series, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_csv(f'{directory}/files.dat', index_col=0).reindex(index=df.index)\n",
    "df[\"tissue\"] = df_files[\"Subtype_Selected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_f = lambda p: 1 if p>0.6 else -1 if p < 0.1 else 0\n",
    "data_df=df.groupby(\"tissue\").mean().applymap(threshold_f).astype(int)\n",
    "df_threshold = df.transpose().drop(\"tissue\", axis=0).applymap(threshold_f).astype(int)\n",
    "data_tensor = tf.convert_to_tensor(data_df.values, dtype=tf.int8)\n",
    "df_threshold_tensor = tf.convert_to_tensor(df_threshold.values.T, dtype=tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hopfield(data_tensor.shape[1])\n",
    "model.load(data_tensor)\n",
    "print(model)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"hopfield\").setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def dilutedhamming(A: tf.Tensor, B: tf.Tensor)-> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Hamming distance of non zero elements (A.B)/lenght(A)\n",
    "\n",
    "    A and be must have the same shape\n",
    "\n",
    "    :param A: first tensor\n",
    "    :param B: second tensor\n",
    "    :return: Distance: 1. if all non-zero elements of A are in B, -1. if all non-zero elements of A are opposite in B\n",
    "    \"\"\"\n",
    "    assert(A.shape==B.shape)\n",
    "    return tf.divide(tf.cast(tf.tensordot(tf.cast(A, tf.float64), tf.cast(B, tf.float64), axes=1), tf.int64),tf.reduce_sum(tf.cast(A != tf.constant(0, A.dtype), tf.int64)))\n",
    "\n",
    "    \n",
    "@tf.function\n",
    "def dilued_predict(sample, data_tensor, model):\n",
    "        reconstructed = tf.cast(model.reconstruct(sample), tf.int64)\n",
    "        return tf.argmax(tf.map_fn(lambda data: tf.cast(dilutedhamming(reconstructed, data), tf.float64), tf.cast(data_tensor,tf.float64), fn_output_signature=tf.float64, parallel_iterations=12), output_type=tf.int64)\n",
    "\n",
    "@tf.function\n",
    "def get_diluted_prediction(samples: tf.Tensor, data_tensor: tf.Tensor, model: Hopfield)-> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Get the nearest memory\n",
    "\n",
    "    :param samples: samples to reconstruct\n",
    "    :param data_tensor: tensor with memories\n",
    "    :param model: model used to infer\n",
    "    :return: tensor with list of argmin of the element of data_tensor nearest to each sample\n",
    "    \"\"\"\n",
    "    return tf.map_fn(lambda sample: dilued_predict(sample, data_tensor, model), samples, fn_output_signature=tf.int64, parallel_iterations=12)\n",
    "\n",
    "\n",
    "def get_predicted_diluted_labels(classes: list, samples: tf.Tensor, data_tensor: tf.Tensor, model:Hopfield)->list:\n",
    "    \"\"\"\n",
    "    Get the classes predicted for each sample\n",
    "\n",
    "    :param classes: list of classes names with shape (nclasses,)\n",
    "    :param samples: samples to reconstruct with shape (nsamples, nspins)\n",
    "    :param data_tensor: tensor with memories (nclasses, nspins)\n",
    "    :return: tensor with list of classes\n",
    "    \"\"\"\n",
    "    return list(map(lambda label_idx: classes[label_idx], get_diluted_prediction(samples, data_tensor, model).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = list(map(lambda sample: get_real_label(df, sample), df.index))\n",
    "#preds = get_predicted_labels(data_df.index, df_threshold_tensor, data_tensor, model)\n",
    "preds = get_predicted_diluted_labels(data_df.index, df_threshold_tensor, data_tensor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acc \",accuracy_score(reals, preds))\n",
    "try:\n",
    "    print(\"AUC \",roc_auc_score(tf.one_hot(tf.unique(preds)[1],3),tf.one_hot(tf.unique(reals)[1],3), multi_class=\"ovr\"))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r,p in zip(data_tensor[0][:10].numpy(),model.reconstruct(data_tensor[0])[:10].numpy()):\n",
    "    print(r,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mem in data_tensor:\n",
    "    plt.hist(mem.numpy().ravel(), histtype=\"step\", lw=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_distance_matrix(data_tensor, model, distance=hamming):\n",
    "    return tf.map_fn(lambda A: tf.map_fn(lambda B: tf.reduce_min([tf.cast(distance(B,model.reconstruct(A)),tf.float64)]), tf.cast(data_tensor,tf.float64), parallel_iterations=6), tf.cast(data_tensor,tf.float64), parallel_iterations=6)\n",
    "\n",
    "dist_matrix = get_distance_matrix(data_tensor, model, dilutedhamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dist_matrix, vmin=-1, vmax=1, xticklabels=data_df.index, yticklabels=data_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_threshold_tensor[np.random.randint(0, df_threshold_tensor.shape[0])]\n",
    "sample = data_tensor[0]\n",
    "reconstructed = model.reconstruct(sample)\n",
    "[dilutedhamming(reconstructed, memory).numpy() for memory in data_tensor], dilued_predict(sample, data_tensor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.clustermap(confusion_matrix(reals, preds, normalize=\"true\"),\n",
    "                    vmin = 0,\n",
    "                    vmax=1,  \n",
    "                    row_cluster=False, \n",
    "                    col_cluster=False, \n",
    "                    xticklabels=data_df.index, \n",
    "                     yticklabels=data_df.index,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"fontsize\":15})\n",
    "ax = cm.ax_heatmap\n",
    "fig = ax.get_figure()\n",
    "ax.set_ylabel(\"real\", fontsize=35, rotation=90)\n",
    "ax.set_yticklabels(labels=data_df.index, rotation=0)\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_label_position(\"left\")\n",
    "\n",
    "ax.set_xticklabels(labels=data_df.index, rotation=90)\n",
    "ax.set_xlabel(\"predicted\",fontsize=35)\n",
    "ax.tick_params(labelsize=35)\n",
    "\n",
    "cax = cm.ax_cbar\n",
    "cax.tick_params(labelsize=30)\n",
    "cax.set_title(\"P()\", fontsize=30)\n",
    "plt.tight_layout()\n",
    "#cm.savefig(f\"predict_{label}.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(data_tensor):\n",
    "    print(data_df.index[i], data_df.index[predict(data, data_tensor, model).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
