{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hopfield4py import Hopfield\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 28, 28\n",
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [load_img(file, color_mode=\"grayscale\", target_size=(w,h), interpolation=\"nearest\") for file in filter(lambda file: \".jpeg\" in file, os.listdir())]\n",
    "#imgs = [array_to_img(x.reshape((28,28,1))) for x in x_train[np.random.randint(0,x_train.shape[1], size=N)].reshape((N,-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "img = imgs[img_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img_arr = img_to_array(img)\n",
    "    img_arr = np.where(img_arr > 255/2, img_arr, 0)\n",
    "    img_arr = np.where(img_arr <= 255/2, img_arr, 1)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_arr = np.array(list(map(preprocess, imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(imgs_arr[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = tf.convert_to_tensor(imgs_arr.reshape((len(imgs_arr),-1)))*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hopfield(data_tensor.shape[1])\n",
    "start = time()\n",
    "model.load(data_tensor)\n",
    "print(time()-start)\n",
    "print(model)\n",
    "start = time()\n",
    "model.train()\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "corrupted_arr = imgs_arr[img_idx].copy()\n",
    "corrupted_arr[15:,5:]=1\n",
    "#corrupted_arr[20:90,10:30]=0\n",
    "array_to_img(corrupted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(imgs_arr[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_arr = model.reconstruct(corrupted_arr.reshape((1,-1)) * 2 - 1).numpy().reshape((w,h, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(reconstructed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X.txt\", imgs_arr.reshape((N,-1)).astype(int), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"corrupted.txt\", corrupted_arr.reshape((1,-1)).astype(int), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(np.genfromtxt(\"reconstructed.csv\", delimiter=\",\").reshape((w,h,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(corrupted_arr).save(\"corrupted.png\")\n",
    "array_to_img(np.genfromtxt(\"reconstructed.csv\", delimiter=\",\").reshape((w,h,1))).save(\"reconstructed.png\")\n",
    "#array_to_img(reconstructed_arr).save(\"reconstructed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-advancement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-terrorist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
