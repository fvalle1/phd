{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from hopfield4py import Hopfield\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 28, 28\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = [load_img(file, color_mode=\"grayscale\", target_size=(w,h), interpolation=\"nearest\") for file in filter(lambda file: \".jpeg\" in file, os.listdir())]\n",
    "imgs = [array_to_img(x.reshape((28,28,1))) for x in x_train[np.random.randint(0,x_train.shape[1], size=N)].reshape((N,-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "img = imgs[img_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img_arr = img_to_array(img)\n",
    "    img_arr = np.where(img_arr > 255/2, img_arr, 0)\n",
    "    img_arr = np.where(img_arr <= 255/2, img_arr, 1)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_arr = np.array(list(map(preprocess, imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(imgs_arr[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = tf.convert_to_tensor(imgs_arr.reshape((len(imgs_arr),-1)))*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Hopfield(data_tensor.shape[1])\n",
    "start = time()\n",
    "model.load(data_tensor)\n",
    "print(time()-start)\n",
    "print(model)\n",
    "start = time()\n",
    "model.train()\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "corrupted_arr = imgs_arr[img_idx].copy()\n",
    "corrupted_arr[10:,15:]=0\n",
    "#corrupted_arr[20:90,10:30]=0\n",
    "array_to_img(corrupted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(imgs_arr[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_arr = model.reconstruct(corrupted_arr.reshape((1,-1)) * 2 - 1).numpy().reshape((w,h, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(reconstructed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X.txt\", imgs_arr.reshape((N,-1)).astype(int), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"corrupted.txt\", corrupted_arr.reshape((1,-1)).astype(int), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(np.genfromtxt(\"reconstructed.csv\", delimiter=\",\").reshape((w,h,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(corrupted_arr).save(\"corrupted.png\")\n",
    "array_to_img(np.genfromtxt(\"reconstructed.csv\", delimiter=\",\").reshape((w,h,1))).save(\"reconstructed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-arrival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-height",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
